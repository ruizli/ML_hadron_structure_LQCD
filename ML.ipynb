{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run statistic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data_anal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper of ML kernals for hadron correlators on lattice\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yaml as yl\n",
    "import sklearn.ensemble as sle\n",
    "import sklearn.tree as slt\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "RandTrn = []\n",
    "RandBC = []\n",
    "RandUnl = []\n",
    "\n",
    "noSaveRand = True\n",
    "\n",
    "# Algorithm depend. params\n",
    "TOL = 1.0e-4\n",
    "MIN_SSPLIT = 2\n",
    "# Minimum #fits\n",
    "MIN_FIT = 1\n",
    "# Minimum #training data\n",
    "MIN_TRAIN = 10\n",
    "# Minimum #bias correction (bc) data\n",
    "MIN_BC = 10\n",
    "# Minimum #unlabeled data\n",
    "MIN_PREDICT = 10\n",
    "PRINT = False\n",
    "SHOW = True\n",
    "\n",
    "# Class to ML fits \n",
    "#   pfile: parameter file\n",
    "class ML_Regression:\n",
    "    def __init__(self, pfile, RandTrn=[], RandBC=[], RandUnl=[]):\n",
    "        params = yl.load(pfile)\n",
    "        # model list: GradiantBoost, DecisionTree, RandomForest, DeepLearning(using Keras)\n",
    "        self.mllist = ['GB', 'DT', 'RF', 'DL']\n",
    "        # pick training data set: Jackknife, Bootstrap, Random, k-fold-CrossValidation\n",
    "        self.tdlist = ['JK', 'BS', 'RM', 'CV', 'CV1']\n",
    "        self.form = params['format']\n",
    "        try:\n",
    "            self.estimator = params['estimate']\n",
    "            self.rate = params['rate']\n",
    "        except:\n",
    "            self.estimator = None\n",
    "            self.rate = None\n",
    "        try:\n",
    "            self.rmseed = params['rmseed']\n",
    "        except:\n",
    "            self.rmseed = 2018\n",
    "        #np.random.seed(self.rmseed)\n",
    "        try:\n",
    "            self.fixRM = params['fixRM']\n",
    "        except:\n",
    "            self.fixRM = False\n",
    "            #self.rmseed = None\n",
    "        #self.dfile = params['dfile']\n",
    "        # method to pick training data set: default to pick first self.trn data\n",
    "        self.nfit = MIN_FIT\n",
    "        self.print = PRINT\n",
    "        self.pre_anly = True\n",
    "        self.fitter_DL = None\n",
    "        try:\n",
    "            self.pred = params['pred']\n",
    "        except:\n",
    "            self.pred = True\n",
    "        self.incbc = True\n",
    "        try:\n",
    "            self.tdset = params['tdset']\n",
    "            #print(self.tdset)\n",
    "            if self.tdset in self.tdlist:\n",
    "                try:\n",
    "                    self.nfit = params['nfit']\n",
    "                except:\n",
    "                    self.nfit = MIN_FIT\n",
    "                if self.tdset == 'JK':\n",
    "                    # Jackknife index\n",
    "                    try:\n",
    "                        self.itdpar = params['tdpar']\n",
    "                    except:\n",
    "                        self.itdpar = 0\n",
    "                    self.tdpar = self.itdpar-1\n",
    "                    self.jk = False\n",
    "                if self.tdset == 'BS':\n",
    "                    self.nfit += 1\n",
    "                    self.bs = False\n",
    "                    try:\n",
    "                        self.fixbs = params['fixRM']\n",
    "                    except:\n",
    "                        self.fixbs = False\n",
    "                    if self.fixbs: \n",
    "                        self.Rtrn = RandTrn\n",
    "                        self.Rbc = RandBC\n",
    "                        self.Runl = RandUnl\n",
    "                # k-fold Cross-validation: 5 <= k <= 10\n",
    "                if 'CV' in self.tdset:\n",
    "                    if self.nfit > 10:\n",
    "                        self.nfit = 10\n",
    "                    #if self.nfit < 5:\n",
    "                    #    self.nfit = 5\n",
    "                    self.nfit += 1\n",
    "                    try:\n",
    "                        self.incbc = params['includeBC']\n",
    "                    except:\n",
    "                        self.incbc = False\n",
    "                    self.cv = False\n",
    "                    try:\n",
    "                        self.fixcv = params['fixRM']\n",
    "                    except:\n",
    "                        self.fixcv = False\n",
    "                    if self.fixcv:\n",
    "                        self.Rm = RandTrn\n",
    "            elif not isinstance(self.tdset, int):\n",
    "                print('Warning: Unknown training data subset identifier! Set to 0\\n')\n",
    "                self.tdset = 0\n",
    "        except:\n",
    "            self.tdset = 0\n",
    "        print(self.tdset)\n",
    "        try:\n",
    "            self.odir = params['odir']\n",
    "            self.osave = True\n",
    "        except:\n",
    "            self.osave = False\n",
    "            self.ofile = None\n",
    "        self.pdir = params['pdir']\n",
    "        self.mlml = params['mlml']\n",
    "        pdfile = open(self.pdir+'/'+self.mlml,'r')\n",
    "        self.pf = yl.load(pdfile)\n",
    "        pdfile.close()\n",
    "        try:\n",
    "            self.anal = params['analysis']\n",
    "        except:\n",
    "            self.anal = False\n",
    "        self.effmass = False\n",
    "        self.ratio = False\n",
    "        self.save_tmpfits = False\n",
    "        self.panal = False\n",
    "        if self.anal: \n",
    "            if self.form == 'pdf':\n",
    "                self.panal = True\n",
    "                self.post_anal = ML_Analyze_PDF(params)\n",
    "                self.save_tmpfits = True\n",
    "            try:\n",
    "                self.effmass = params['effmass']\n",
    "            except:\n",
    "                self.effmass = False\n",
    "            try:\n",
    "                self.ratio = params['ratio']\n",
    "            except:\n",
    "                self.ratio = False\n",
    "        # list of Y momentum\n",
    "        self.prY = params['momentum_Y']\n",
    "        # list of Y z's\n",
    "        self.zrY = params['z_Y']\n",
    "        try:\n",
    "            self.prX = params['momentum_X']\n",
    "            if len(list(self.prX)) == 0:\n",
    "                self.prX = None\n",
    "        except:\n",
    "            self.prX = None\n",
    "        try:\n",
    "            self.zrX = params['z_X']\n",
    "            if len(list(self.zrX)) == 0:\n",
    "                self.zrX = None\n",
    "        except:\n",
    "            self.zrX = None\n",
    "        try:\n",
    "            self.orY = params['operator_Y']\n",
    "            if len(list(self.orY))==0:\n",
    "                self.orY = [None]\n",
    "        except:\n",
    "            self.orY = [None]\n",
    "        try:\n",
    "            self.orX = params['operator_X']\n",
    "            if len(list(self.orX))==0:\n",
    "                self.orX = [None]\n",
    "        except:\n",
    "            self.orX = [None]\n",
    "        try:\n",
    "            self.srY = params['T_Y']\n",
    "        except:\n",
    "            self.srY = [None]\n",
    "        try:\n",
    "            self.srX = params['T_X']\n",
    "        except:\n",
    "            self.srX = [None]\n",
    "        # list of Y time slices\n",
    "        try:\n",
    "            self.tr = params['ts_Y']\n",
    "            if self.tr is None:\n",
    "                self.tr = [None]\n",
    "            elif len(list(self.tr)) == 0:\n",
    "                self.tr = [None]\n",
    "        except: \n",
    "            self.tr = [None]\n",
    "        # list of X & Y time differences\n",
    "        self.dtr = params['dts_X']\n",
    "        # number of sources per configuration\n",
    "        try:\n",
    "            self.tfold = params['nsrc']\n",
    "        except:\n",
    "            self.tfold = 0\n",
    "        self.ntrn = params['ntrn']\n",
    "        if isinstance(self.ntrn, (int, str)):\n",
    "            assert(int(self.ntrn) >= MIN_TRAIN)\n",
    "            self.ntrn = [int(self.ntrn)]\n",
    "        else:\n",
    "            assert(len(self.ntrn) == len(self.prX))\n",
    "        self.nbc = params['nbc']\n",
    "        if isinstance(self.nbc, (int, str)):\n",
    "            assert(int(self.nbc) >= MIN_BC)\n",
    "            self.nbc = [int(self.nbc)]\n",
    "        else:\n",
    "            assert(len(self.nbc) == len(self.prX))\n",
    "        # read in data stored in data pool 'database'\n",
    "        # params[]: \n",
    "        #     format (data format, 'raw','pdf'); \n",
    "        #     binsize (data bin); \n",
    "        #     ddir (data files directory)\n",
    "        #     dfile.x (X data filename); \n",
    "        #     dfile.y (Y data filename);\n",
    "        self.database = Data_IO(params, self.tdset)\n",
    "        self.data = None\n",
    "        self.ndata = 0\n",
    "        self.model = None\n",
    "        self.fitnow = None\n",
    "        self.isset = False\n",
    "        self.errscale = None\n",
    "        self.date = self.database.date #datetime.datetime.today().strftime('%m%d%Y')\n",
    "        # Data IO, moved to the io kernel \n",
    "        return\n",
    "    \n",
    "    # clear data, free memory\n",
    "    def finalize(self): \n",
    "        if self.panal: \n",
    "            self.post_anal.finalize()\n",
    "        self.cleanup_data()\n",
    "        self.del_data()\n",
    "        self.database.finalize()\n",
    "        if (self.tdset == 'BS') and (self.fixbs is True):\n",
    "            del self.Rtrn\n",
    "            del self.Rbc\n",
    "            del self.Runl\n",
    "            self.Rtrn = None\n",
    "            self.Rbc = None\n",
    "            self.Runl = None\n",
    "        if 'CV' in self.tdset:\n",
    "            del self.Rm\n",
    "            self.Rm = None\n",
    "        return\n",
    "        \n",
    "    # Initialize fits\n",
    "    # Select correlator characters, p (momentum), z (Wilson link lenght), t (sink time slice), etc., \n",
    "    #        data sets, and assign the fit model\n",
    "    def inifit(self, fdparX, fdparY, indx):\n",
    "        self.ftag = None\n",
    "        self.dtag = None\n",
    "        self.p = None\n",
    "        self.c = None\n",
    "        self.y = None\n",
    "        if self.del_data: \n",
    "            self.data = {}\n",
    "            self.add2pt = False\n",
    "            if self.ratio:\n",
    "                #print(\"Y tags are {:}\".format(fdparY))\n",
    "                deltagY, self.ftag, self.spectag, self.data['Y'], self.data['S'], self.dmeanY, self.dstdY = self.database.select_data(fdparY, 'Y', self.ratio)\n",
    "                self.n2pt = len(self.spectag)\n",
    "                self.add2pt = (self.n2pt > 0)\n",
    "            else:\n",
    "                deltagY, self.ftag, self.data['Y'], self.dmeanY, self.dstdY = self.database.select_data(fdparY, 'Y', self.ratio)\n",
    "                self.n2pt = 0\n",
    "            if self.data['Y'].shape[0]==0:\n",
    "                self.ny=0\n",
    "                self.nx=0\n",
    "                self.fitnow = self.nfit\n",
    "                return\n",
    "            self.dtX, self.dtag, self.data['X'], self.dmeanX, self.dstdX = self.database.select_data(fdparX, 'X')       \n",
    "        #print(\"self.data['X'] is {:}\".format(self.data['X']))\n",
    "        self.ndata = self.data['X'].shape[0]\n",
    "        if self.ndata > self.data['Y'].shape[0]:\n",
    "            self.ndata = self.data['Y'].shape[0]\n",
    "        if 'CV' in self.tdset:\n",
    "            self.mlscr = []\n",
    "            self.mlscr0 = []\n",
    "            self.cvbs = []\n",
    "            self.cv = False\n",
    "            #if self.ndata / (self.nfit-1) < 50:\n",
    "             #   self.nfit = int(self.ndata/50.0) + 1\n",
    "        self.nx = self.data['X'].shape[1]\n",
    "        self.ny = len(self.ftag) #self.data['Y'].shape[1]\n",
    "        self.Ny = self.n2pt + self.ny\n",
    "        print(\"Shape of X / Y : {:} / {:}\".format(self.nx, self.ny))\n",
    "        try:\n",
    "            self.trn = self.ntrn[indx]\n",
    "        except:\n",
    "            self.trn = self.ntrn[0]\n",
    "        try:\n",
    "            self.bc = self.nbc[indx]\n",
    "        except:\n",
    "            self.bc = self.nbc[0]\n",
    "        self.lbl = self.trn + self.bc\n",
    "        self.unlbl = self.ndata - self.lbl\n",
    "        if self.tdset == 'JK':\n",
    "            self.nfit = int(self.trn) + 1\n",
    "            self.tdpar = self.itdpar-1\n",
    "            self.jk = False\n",
    "        if self.tdset == 'BS':\n",
    "            self.bs = False\n",
    "        # verify number of train & test data\n",
    "        if ('CV' in self.tdset) and (int(self.ndata / self.unlbl) != self.nfit-1):\n",
    "            if self.tdset == 'CV':\n",
    "                self.unlbl = int(self.ndata/(self.nfit-1))\n",
    "                self.lbl = self.ndata - self.unlbl\n",
    "            else:\n",
    "                self.lbl = int(self.ndata/(self.nfit-1))\n",
    "                self.unlbl = self.ndata - self.lbl\n",
    "            if self.incbc:\n",
    "                self.trn = int(self.trn*self.lbl/(self.trn+self.bc))\n",
    "                self.bc = self.lbl-self.trn\n",
    "            else:\n",
    "                self.trn = self.lbl\n",
    "                self.bc = 0\n",
    "        self.bin = int((self.ndata+self.lbl-1)/self.lbl)\n",
    "        self.bin = 1\n",
    "        self.data_reorder()\n",
    "        if self.tdset == 'JK' or self.tdset == 'RM':\n",
    "            self.N = self.data['X'][self.lbl:]\n",
    "            self.P = self.data['Y'][self.lbl:]\n",
    "        if self.model != None:\n",
    "            del self.model\n",
    "        self.model = self.make_model(indx)\n",
    "        self.isset = False\n",
    "        self.errscale = None\n",
    "        self.fitnow = 0\n",
    "        if self.osave:\n",
    "            self.database.dfile_mkheader(indx)\n",
    "            self.ml_mkheader()\n",
    "        #print(\"self.data['X'] is {:}\".format(self.data['X']))\n",
    "        if self.panal:\n",
    "            print(\"Adding table\")\n",
    "            self.post_anal.add_table(self.database.NT, self.ndata, self.trn, self.bc, pztY=self.ftag, pztX=self.dtag)\n",
    "            print(\"Finishing adding table\")\n",
    "            \n",
    "    def isfit(self):\n",
    "        return self.fitnow < self.nfit\n",
    "        \n",
    "    # Reorder data (scatter)\n",
    "    def data_reorder(self):\n",
    "        #print(\"self.data['X'] is {:}\".format(self.data['X']))\n",
    "        tmpx = self.data['X']\n",
    "        tmpy = self.data['Y']\n",
    "        self.data['X'] = []\n",
    "        self.data['Y'] = []\n",
    "        if self.add2pt:\n",
    "            tmps = self.data['S']\n",
    "            self.data['S'] = []\n",
    "        for i in range(self.bin):\n",
    "            self.data['X'].extend(tmpx[i:self.ndata:self.bin].tolist())\n",
    "            self.data['Y'].extend(tmpy[i:self.ndata:self.bin].tolist())\n",
    "            if self.add2pt:\n",
    "                self.data['S'].extend(tmps[i:self.ndata:self.bin].tolist())\n",
    "        del tmpx\n",
    "        del tmpy\n",
    "        if self.add2pt:\n",
    "            del tmps\n",
    "        #print(\"self.data['X'] is {:}\".format(self.data['X']))\n",
    "\n",
    "    # build up the fit model\n",
    "    def make_model(self, indx=None):\n",
    "        assert(self.mlml in self.mllist) \n",
    "        if self.mlml == 'GB':\n",
    "            return self.make_model_GB(indx)\n",
    "        elif self.mlml == 'DT':\n",
    "            return self.make_model_DT()\n",
    "        elif self.mlml == 'RF':\n",
    "            return self.make_model_RF()\n",
    "        else:\n",
    "            return self.make_model_DL()\n",
    "        \n",
    "    def ml_mkheader(self):\n",
    "        if self.osave is False: \n",
    "            return\n",
    "        pf = open(self.database.ofile, 'a')\n",
    "        if self.mlml == 'GB': \n",
    "            pf.write(\"\\n GB parameters: (random seed {:}) \\n nestimator:  {:} \\n \\\n",
    "            lnrate:  {:} \\n lossfunc:  {:} \\n subsample:  {:} \\n \\\n",
    "            max_depth:  {:} \\n lntol:  {:} \\n verbose:  {:} \\n\\n\".format(self.rmseed, self.GB_nestimator, \n",
    "                                                                         self.GB_lnrate, self.GB_lossfunc, self.GB_ssample, \n",
    "                                                                         self.GB_mdth, self.GB_tol, self.GB_verbose))\n",
    "        pf.close()\n",
    "        return\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    def make_model_GB(self, indx=None):\n",
    "        if indx is None:\n",
    "            self.GB_nestimator = self.pf['nestimator']\n",
    "            self.GB_lnrate = self.pf['lnrate']\n",
    "        else:\n",
    "            try:\n",
    "                self.GB_nestimator = self.estimator[indx]\n",
    "                self.GB_lnrate = self.rate[indx]\n",
    "            except:\n",
    "                self.GB_nestimator = self.pf['nestimator']\n",
    "                self.GB_lnrate = self.pf['lnrate']\n",
    "        try:\n",
    "            self.GB_lossfunc = self.pf['lossfunc']\n",
    "        except:\n",
    "            self.GB_lossfunc = 'ls'\n",
    "        try:\n",
    "            self.GB_ssample = self.pf['subsample'] #= float(self.trn) / float(self.ndata)\n",
    "            GB_schn = int(10/self.GB_ssample)\n",
    "        except:\n",
    "            self.GB_ssample = 1.0\n",
    "            GB_schn = 1\n",
    "        try:\n",
    "            self.GB_mdth = self.pf['max_depth']\n",
    "        except:\n",
    "            self.GB_mdth = 3\n",
    "        try:\n",
    "            self.GB_tol = self.pf['lntol']\n",
    "        except:\n",
    "            self.GB_tol = TOL\n",
    "        try:\n",
    "            self.GB_verbose = self.pf['verbose']\n",
    "        except:\n",
    "            self.GB_verbose = False\n",
    "        print(\"GB parameter rate is {:}\".format(self.GB_lnrate))\n",
    "        model = [ sle.GradientBoostingRegressor(loss=self.GB_lossfunc, learning_rate=self.GB_lnrate, \n",
    "                                             n_estimators=self.GB_nestimator, max_depth=self.GB_mdth, \n",
    "                                             subsample=self.GB_ssample,\n",
    "                                            tol=self.GB_tol) #for j in range(GB_schn) ]\n",
    "                 for i in range(self.ny) ]\n",
    "        #self.ml_mkheader()\n",
    "        return model\n",
    "        \n",
    "    # Decistion Tree\n",
    "    def make_model_DT(self):\n",
    "        try:\n",
    "            self.DT_ctr = self.pf['criterion']\n",
    "        except:\n",
    "            self.DT_ctr = 'mse'\n",
    "        self.DT_mdth = None\n",
    "        self.DT_mspt = None\n",
    "        try:\n",
    "            self.DT_mspt = self.pf['min_samples_split']\n",
    "        except:\n",
    "            try:\n",
    "                self.DT_mdth = self.pf['max_depth']\n",
    "                self.DT_mspt = None\n",
    "            except:\n",
    "                self.DT_mspt = MIN_SSPLIT\n",
    "                self.DT_mdth = None\n",
    "        try:\n",
    "            self.DT_verbose = self.pf['verbose']\n",
    "        except:\n",
    "            self.DT_verbose = False\n",
    "        model = [ slt.DecisionTreeRegressor(criterion=self.DT_ctr, max_depth=self.DT_mdth,\n",
    "                                        min_samples_split=self.DT_mspt)\n",
    "                 for i in range(self.ny) ]\n",
    "        return model\n",
    "            \n",
    "    # Random Foreast\n",
    "    def make_model_RF(self):\n",
    "        # FIXME\n",
    "        return None\n",
    "    \n",
    "    def make_model_DL(self):\n",
    "        self.fitter_DL = DL_Regression(self.pf, self.ny)\n",
    "        return self.fitter_DL.model\n",
    "    \n",
    "    def make_oheader(self, parY, parX, indx):\n",
    "        self.database.dfile_mkheader()\n",
    "        self.ml_mkheader()\n",
    "        return\n",
    "    \n",
    "    # set up data: Train [X,Y]; BC [B,C]; Unlabeled [N,P]\n",
    "    def setup_data(self):\n",
    "        self.fitnow += 1\n",
    "        if self.save_tmpfits: \n",
    "            self.post_anal.append_table(self.database.odir)\n",
    "        if self.isset:\n",
    "            return True\n",
    "        if isinstance(self.tdset, int):\n",
    "            try:\n",
    "                self.X = self.data['X'][self.tdset:self.tdset+self.trn]\n",
    "                self.Y = self.data['Y'][self.tdset:self.tdset+self.trn]\n",
    "                self.B = self.data['X'][self.tdset+self.trn:self.tdset+self.trn+self.bc]\n",
    "                self.C = self.data['Y'][self.tdset+self.trn:self.tdset+self.trn+self.bc]\n",
    "                if self.add2pt:\n",
    "                    self.S = self.data['S'][self.tdset:]\n",
    "            except:\n",
    "                print('Labeled data subset out of index range!\\n')\n",
    "                sys.exit()\n",
    "            self.N = list(self.data['X'][self.tdset+self.lbl:])\n",
    "            self.P = list(self.data['Y'][self.tdset+self.lbl:])\n",
    "            if self.tdset > 0:\n",
    "                self.N.extend(self.data['X'][:self.tdset])\n",
    "                self.P.extend(self.data['Y'][:self.tdset])\n",
    "                if self.add2pt:\n",
    "                    self.S.extend(self.data['S'][:self.tdset])\n",
    "            self.tdset+=1\n",
    "        else:\n",
    "            if self.tdset == 'JK':\n",
    "                if self.jk: \n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    if self.add2pt:\n",
    "                        self.S = []\n",
    "                    self.tdpar+=1\n",
    "                    if self.tdpar < 0 or self.tdpar > self.trn:\n",
    "                        return self.isset\n",
    "                    if self.tdpar > 0:\n",
    "                        self.X.extend(self.data['X'][:self.tdpar])\n",
    "                        self.Y.extend(self.data['Y'][:self.tdpar])\n",
    "                        if self.add2pt:\n",
    "                            self.S.extend(self.data['S'][:self.tdpar])\n",
    "                    if self.tdpar < self.trn:\n",
    "                        self.X.extend(self.data['X'][self.tdpar+1:self.trn+1])\n",
    "                        self.Y.extend(self.data['Y'][self.tdpar+1:self.trn+1])\n",
    "                        if self.add2pt:\n",
    "                            self.S.extend(self.data['S'][self.tdpar+1:self.trn+1])\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.B.extend(self.data['X'][self.trn+1:self.lbl])\n",
    "                    self.B.append(self.data['X'][self.tdpar])\n",
    "                    self.C.extend(self.data['Y'][self.trn+1:self.lbl])\n",
    "                    self.C.append(self.data['Y'][self.tdpar])\n",
    "                    if self.add2pt:\n",
    "                        self.S.extend(self.data['S'][self.trn+1:self.lbl])\n",
    "                        self.S.append(self.data['S'][self.tdpar])\n",
    "                        self.S.extend(self.data['S'][self.lbl:])\n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    #self.N = self.data['X'][self.lbl:]\n",
    "                    #self.P = self.data['Y'][self.lbl:]\n",
    "                    if self.add2pt:\n",
    "                        self.S = self.data['S'].copy()\n",
    "                    self.jk = True\n",
    "            elif self.tdset == 'BS':\n",
    "                if self.bs:\n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.N = []\n",
    "                    self.P = []\n",
    "                    if self.add2pt:\n",
    "                        self.S = []\n",
    "                    if self.fixbs:\n",
    "                        if len(self.Rtrn) < self.nfit-1:\n",
    "                            self.Rtrn.append(np.random.randint(0, self.lbl, self.trn))\n",
    "                            #RandTrn = np.array(self.Rtrn)\n",
    "                            #print(\"RandTrn is {:}\".format(RandTrn))\n",
    "                        if len(self.Rbc) < self.nfit-1:\n",
    "                            self.Rbc.append(np.random.randint(0, self.lbl, self.bc))\n",
    "                            #RandBC = np.array(self.Rbc)\n",
    "                            #print(\"RandBC is {:}\".format(RandBC))\n",
    "                        if len(self.Runl) < self.nfit-1: \n",
    "                            self.Runl.append(np.random.randint(self.lbl,self.ndata, self.unlbl))\n",
    "                            #RandUnl = np.array(self.Runl)\n",
    "                            #print(\"RandUnl is {:}\".format(RandUnl))\n",
    "                    for i in range(self.trn):\n",
    "                        if self.fixbs:\n",
    "                            r = self.Rtrn[self.fitnow-2][i]\n",
    "                        else:\n",
    "                            r = np.random.randint(0,self.lbl)\n",
    "                        self.X.append(self.data['X'][r])\n",
    "                        self.Y.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.bc):\n",
    "                        if self.fixbs:\n",
    "                            r = self.Rbc[self.fitnow-2][i]\n",
    "                        else:\n",
    "                            r = np.random.randint(0,self.lbl)\n",
    "                        #r = np.random.randint(0,self.lbl)\n",
    "                        #print(\"Rand is {:}\".format(r))\n",
    "                        self.B.append(self.data['X'][r])\n",
    "                        self.C.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.unlbl):\n",
    "                        if self.fixbs:\n",
    "                            r = self.Runl[self.fitnow-2][i]\n",
    "                        else:\n",
    "                            r = np.random.randint(self.lbl,self.ndata)\n",
    "                        #r = np.random.randint(self.lbl,self.ndata)\n",
    "                        self.N.append(self.data['X'][r])\n",
    "                        self.P.append(self.data['Y'][r]) \n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    self.N = self.data['X'][self.lbl:]\n",
    "                    self.P = self.data['Y'][self.lbl:]\n",
    "                    if self.add2pt:\n",
    "                        self.S = self.data['S'].copy()\n",
    "                    self.bs = True\n",
    "            elif self.tdset == 'CV':\n",
    "                if (self.fitnow-1)*self.unlbl > self.ndata:\n",
    "                    self.isset = False\n",
    "                    self.fitnow = self.nfit\n",
    "                    if self.save_tmpfits:\n",
    "                        self.post_anal.pop_table()\n",
    "                    return False\n",
    "                if self.cv:\n",
    "                    stcv = (self.fitnow-2)*(self.unlbl) \n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.N = []\n",
    "                    self.P = []\n",
    "                    if self.add2pt:\n",
    "                        self.S = []\n",
    "                    if len(self.Rm) < self.ndata:\n",
    "                        self.Rm = np.random.permutation(self.ndata)\n",
    "                    for i in range(self.trn):\n",
    "                        r = self.Rm[(stcv+self.unlbl+i)%self.ndata]\n",
    "                        self.X.append(self.data['X'][r])\n",
    "                        self.Y.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.bc):\n",
    "                        r = self.Rm[(stcv+self.unlbl+self.trn+i)%self.ndata]\n",
    "                        self.B.append(self.data['X'][r])\n",
    "                        self.C.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.unlbl):\n",
    "                        r = self.Rm[(stcv+i)%self.ndata]\n",
    "                        self.N.append(self.data['X'][r])\n",
    "                        self.P.append(self.data['Y'][r]) \n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    self.N = self.data['X'][self.lbl:]\n",
    "                    self.P = self.data['Y'][self.lbl:]\n",
    "                    if self.add2pt:\n",
    "                        self.S = self.data['S'].copy()\n",
    "                    self.cv = True\n",
    "            elif self.tdset == 'CV1':\n",
    "                if (self.fitnow-1)*self.lbl > self.ndata:\n",
    "                    self.isset = False\n",
    "                    self.fitnow = self.nfit\n",
    "                    if self.save_tmpfits:\n",
    "                        self.post_anal.pop_table()\n",
    "                    return False\n",
    "                if self.cv:\n",
    "                    stcv = (self.fitnow-2)*(self.lbl) \n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.N = []\n",
    "                    self.P = []\n",
    "                    if self.add2pt:\n",
    "                        self.S = []\n",
    "                    if len(self.Rm) < self.ndata:\n",
    "                        self.Rm = np.random.permutation(self.ndata)\n",
    "                    for i in range(self.trn):\n",
    "                        r = self.Rm[stcv+i]\n",
    "                        self.X.append(self.data['X'][r])\n",
    "                        self.Y.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.bc):\n",
    "                        r = self.Rm[(stcv+self.trn+i)]\n",
    "                        self.B.append(self.data['X'][r])\n",
    "                        self.C.append(self.data['Y'][r])\n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                    for i in range(self.unlbl):\n",
    "                        r = self.Rm[(stcv+self.lbl+i)%self.ndata]\n",
    "                        self.N.append(self.data['X'][r])\n",
    "                        self.P.append(self.data['Y'][r]) \n",
    "                        if self.add2pt:\n",
    "                            self.S.append(self.data['S'][r])\n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    self.N = self.data['X'][self.lbl:]\n",
    "                    self.P = self.data['Y'][self.lbl:]\n",
    "                    if self.add2pt:\n",
    "                        self.S = self.data['S'].copy()\n",
    "                    self.cv = True\n",
    "            else:\n",
    "                pm = np.random.permutation(self.lbl)\n",
    "                self.X = [self.data['X'][pm[i]] for i in range(self.trn)]\n",
    "                self.B = [self.data['X'][pm[i]] for i in range(self.trn,self.lbl)]\n",
    "                self.Y = [self.data['Y'][pm[i]] for i in range(self.trn)]\n",
    "                self.C = [self.data['Y'][pm[i]] for i in range(self.trn,self.lbl)]\n",
    "                if self.add2pt:\n",
    "                    self.S = [ self.data['S'][i] for i in pm ]\n",
    "        self.isset = True\n",
    "        return self.isset\n",
    "        \n",
    "    def del_data(self):\n",
    "        if self.data == None:\n",
    "            return True\n",
    "        if 'X' in self.data:\n",
    "            del self.data['X']\n",
    "        if 'Y' in self.data:\n",
    "            del self.data['Y']\n",
    "        if 'S' in self.data:\n",
    "            del self.data['S']\n",
    "        self.data = None\n",
    "        try:\n",
    "            del self.mlscr\n",
    "            del self.mlscr0\n",
    "            del self.cvbs\n",
    "        except:\n",
    "            pass\n",
    "        del self.dmeanX\n",
    "        del self.dmeanY\n",
    "        del self.dstdY\n",
    "        del self.dstdX\n",
    "        self.dmeanX = None\n",
    "        self.dmeanY = None\n",
    "        self.dstdY = None\n",
    "        self.dstdX = None\n",
    "        return True\n",
    "    \n",
    "    # clean up data\n",
    "    def cleanup_data(self):\n",
    "        if self.isset is False:\n",
    "            return \n",
    "        if self.tdset in self.tdlist:\n",
    "            del self.X\n",
    "            del self.Y\n",
    "            del self.B\n",
    "            del self.C\n",
    "        if self.tdset == 'BS' or isinstance(self.tdset, int):\n",
    "            del self.N\n",
    "            del self.P\n",
    "        if self.y is not None:\n",
    "            del self.y\n",
    "            del self.c\n",
    "            del self.p\n",
    "            self.y = None\n",
    "            self.c = None\n",
    "            self.p = None\n",
    "        if self.add2pt:\n",
    "            del self.S\n",
    "        self.isset = False\n",
    "        return\n",
    "    \n",
    "    # Plot data statistics: histograms, density, correlations\n",
    "    def data_statistic(self, data, tag = None):\n",
    "        ddf = Dataframe(data, tag=tag)\n",
    "        print(ddf.data.describe())\n",
    "        binmin, atc = ddf.autocorr(0.1)\n",
    "        print('Data blocksize {:d} with autocorrelation {:f} \\n'.format(binmin, atc))\n",
    "        print(\"self.nx is {:}\".format(self.nx))\n",
    "        ddf.hist((self.nx,None),self.database.pltfile)\n",
    "        ddf.density((self.nx,None),self.database.pltfile)\n",
    "        ddf.covplot(prange=((0, self.nx), (self.nx, None)), out=self.database.pltfile)\n",
    "        return\n",
    "        \n",
    "\n",
    "    # Prediction bias Correction\n",
    "    def bias_crrt(self):\n",
    "        if self.c is not None:\n",
    "            del self.c\n",
    "            self.c = None\n",
    "        if self.p is not None:\n",
    "            del self.p\n",
    "            self.p = None\n",
    "        if self.y is not None:\n",
    "            del self.y\n",
    "            self.y = None\n",
    "        if self.incbc:\n",
    "            self.c = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.B).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        self.p = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.N).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        if (self.tdset=='JK') and (self.fitnow==1):\n",
    "            if self.osave:\n",
    "                pf = open(self.database.ofile, 'a+')\n",
    "                pf.write(\"Bias correction data statistic: {:} +/- {:}\\n\".format(np.array(self.C).mean(axis=0)[0]*self.dmeanY[0], self.dmeanY[0]*np.array(self.C).std(axis=0, ddof=1)[0]/math.sqrt(len(self.C))))\n",
    "                pf.close()\n",
    "        # Cross-validation: Add prediction scores\n",
    "        if 'CV' in self.tdset and self.cv:\n",
    "            self.mlscr.append(np.array([self.model[i].score(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.N).tolist(), np.array(self.P).T[i].tolist()) \n",
    "                            for i in range(self.ny)]))\n",
    "            self.mlscr0.append(np.array([self.model[i].score(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.X).tolist(), np.array(self.Y).T[i].tolist()) \n",
    "                            for i in range(self.ny)]))\n",
    "            self.cvbs.append(np.array(self.Y).mean(axis=0) - self.p.mean(axis=1))\n",
    "        if self.incbc:\n",
    "            C_arr = np.ndarray(shape=(self.bc,self.ny),buffer=np.array(self.C)).T\n",
    "        # Prediction matrix of size ny*ndata\n",
    "        self.y = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.X).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        predata = np.array([self.model[i].predict(\n",
    "            self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.data['X']).tolist())  \n",
    "                            for i in range(self.ny)])\n",
    "        print(predata.shape)\n",
    "        omat = np.ndarray(shape=(2*self.ny, self.ndata), \n",
    "                          buffer=np.array([\n",
    "                              predata.tolist(), \n",
    "                              np.array(self.data['Y']).T.tolist()]))\n",
    "                     #     dtype=float)\n",
    "        # generate covariance matrix, predictions first\n",
    "        ocov = np.cov(omat)\n",
    "        print('shape of OCOV: {:}'.format(ocov.shape))\n",
    "        if self.incbc:\n",
    "            # Bias correction equation\n",
    "            obc = np.array([self.p[i].mean() + C_arr[i].mean() - self.c[i].mean() for i in range(self.ny)])\n",
    "            for o in obc:\n",
    "                print(o)\n",
    "        else:\n",
    "            obc = np.array([self.p[i].mean() for i in range(self.ny)])\n",
    "        s2 = np.array([ocov[i,i]/ocov[i+self.ny,i+self.ny] for i in range(self.ny)])\n",
    "        r = np.array([(ocov[i,i+self.ny]**2/(ocov[i,i]*ocov[i+self.ny,i+self.ny])) for i in range(self.ny)])\n",
    "        osigma = np.array([ocov[i+self.ny,i+self.ny] for i in range(self.ny)])\n",
    "        srs2r = np.array([math.sqrt(s2[i]*r[i]) for i in range(self.ny)])\n",
    "        if self.incbc:\n",
    "            bcvar = osigma/self.lbl*(s2*self.lbl/self.unlbl + (1.+s2-2.*srs2r)*self.lbl/self.bc)\n",
    "        else:\n",
    "            bcvar = osigma*s2/self.unlbl\n",
    "        if self.errscale is None:\n",
    "            if self.incbc:\n",
    "                self.errscale = (s2*self.lbl/self.unlbl + (1.+s2-2.*srs2r)*self.lbl/self.bc)/self.lbl\n",
    "            else:\n",
    "                self.errscale = s2*self.lbl/self.unlbl\n",
    "            self.errscale = np.array([math.sqrt(self.errscale[i]) for i in range(self.ny)])\n",
    "            print(\"Correlation coefficient between Pred. & Obsd. {:}\".format([math.sqrt(r[i]) for i in range(self.ny)]))\n",
    "            print(\"error scale: {:}\".format(self.errscale))\n",
    "            if False: #if self.anal:\n",
    "                self.post_anal.extend_table('errscl', self.errscale)\n",
    "            if self.osave: \n",
    "                pf = open(self.database.ofile, 'a+')\n",
    "                pf.write(\"Correlation coefficient between Pred. & Obsd. {:}\\n\".format([math.sqrt(r[i]) for i in range(self.ny)]))\n",
    "                pf.write(\"error scale: {:}\\n\".format(self.errscale))\n",
    "                pf.close()\n",
    "        return (obc, np.array([math.sqrt(bcvar[i]) for i in range(self.ny)]))\n",
    "    \n",
    "    def imp_prdt(self, bc):\n",
    "        return bc\n",
    "    \n",
    "    def add_anal(self):\n",
    "        if self.save_tmpfits:\n",
    "            #self.post_anal.extend_table({\"ycov\": ocov})\n",
    "          #  self.post_anal.extend_table({\"ymean\": obc})\n",
    "           # self.post_anal.extend_table({\"y\": omat})\n",
    "            if False: #for i in range(self.ny):\n",
    "                print(\"{:}: {:}\".format(self.ftag[i], np.array(self.Y).T[i]))\n",
    "            if self.incbc:\n",
    "                self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=np.array(self.Y).T, dbc=np.array(self.C).T, \n",
    "                                    dunlbl=np.array(self.P).T, pred=False, overwrite=True)\n",
    "            else:\n",
    "                self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=np.array(self.Y).T, dbc=None, \n",
    "                                    dunlbl=np.array(self.P).T, pred=False, overwrite=True)\n",
    "            if self.pred:\n",
    "                if self.incbc:\n",
    "                    self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=self.y, dbc=self.c, \n",
    "                                    dunlbl=self.p, pred=None, overwrite=True)\n",
    "                else:\n",
    "                    self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=self.y, dbc=None, \n",
    "                                    dunlbl=self.p, pred=True, overwrite=True)\n",
    "            if self.effmass:\n",
    "                self.post_anal.effmass(tag=self.ftag, pred=False)\n",
    "                #self.post_anal.effmass(tag=self.ftag, pred=False, subset=1)\n",
    "                #self.post_anal.effmass(tag=self.ftag, pred=False, subset=2)\n",
    "                \n",
    "                if self.pred:\n",
    "                    self.post_anal.effmass(tag=self.ftag, pred=True)\n",
    "                    if self.incbc:\n",
    "                        self.post_anal.effmass(tag=self.ftag, pred=None)\n",
    "            if self.ratio:\n",
    "                if self.add2pt:\n",
    "                    self.post_anal.add_data(tag=self.spectag, #dscale=self.dmeanY, \n",
    "                                        #dtrn=np.array(self.Y).T[self.ny:,:], \n",
    "                                        #dbc=np.array(self.C).T[self.ny:,:], dunlbl=np.array(self.P).T[self.ny:,:], \n",
    "                                        data=np.array(self.S).T, \n",
    "                                        pred=False, NT=self.database.NT, is2pt=True)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, pred=False)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, subset=1, pred=False)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, subset=2, pred=False)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, subset=0, pred=False)\n",
    "                if self.pred:\n",
    "                    if self.incbc:\n",
    "                        self.post_anal.ratio3ptn2pt(tag=self.ftag, pred=None)\n",
    "                    self.post_anal.ratio3ptn2pt(tag=self.ftag, pred=True)\n",
    "        return\n",
    "        \n",
    "    # Post-fits analysis\n",
    "    def analyze(self, bc, pd, dmeanY, stdY):\n",
    "        if self.ny==0:\n",
    "            return\n",
    "        if self.osave:\n",
    "            pf = open(self.database.ofile, 'a+')\n",
    "        if self.pred:\n",
    "            scr = np.array([self.model[i].score(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.data['X']).tolist(), \n",
    "                np.array(self.data['Y']).T.tolist()[i]) for i in range(self.ny)])\n",
    "            # Cross-validation: Prediction score statistics\n",
    "            if 'CV' in self.tdset:\n",
    "                scrmean = np.array(self.mlscr).mean(axis=0)\n",
    "                scrmean0 = np.array(self.mlscr0).mean(axis=0)\n",
    "                scrstd = np.array(self.mlscr).std(axis=0,ddof=1)\n",
    "                scrstd0 = np.array(self.mlscr0).std(axis=0,ddof=1)\n",
    "                bs = np.array(self.cvbs).mean(axis=0) * self.dmeanY\n",
    "                bss = np.array(self.cvbs).std(axis=0,ddof=1) * self.dmeanY#/abs(bs)\n",
    "            if self.tdset == 'BS' or self.tdset == 'JK':\n",
    "                oimp = np.array(np.array(pd[1:]).reshape(2*len(pd[1:]),self.ny)[::2]).T\n",
    "                oimpstd = np.array(np.array(pd[1:]).reshape(2*len(pd[1:]),self.ny)[1::2]).T\n",
    "                print(\"OIMP is {:}\\n\".format(oimp))\n",
    "                omean = np.array([oimp[i].mean() for i in range(self.ny)])\n",
    "                omeanstd = np.array([oimpstd[i].mean() for i in range(self.ny)])\n",
    "                #print(omean)\n",
    "                ostd = np.array([oimp[i].std(ddof=1) for i in range(self.ny)])\n",
    "                oymean1 = np.array(dmeanY[1:]).mean(axis=0)\n",
    "                oystd1 = np.array(stdY[1:]).mean(axis=0) #np.array(dmeanY[1:]).std(axis=0, ddof=1)\n",
    "                if self.tdset == 'BS':\n",
    "                    print(pd[0][0])\n",
    "                    obc = 2.*pd[0][0]-omean\n",
    "                    oymean1 = 2.*dmeanY[0] - oymean1\n",
    "                else:\n",
    "                    obc = omean #self.lbl*pd[0][0]-(self.lbl-1)*omean\n",
    "                    print(\"OBC is {:}\\n\".format(obc))\n",
    "                    ostd *= (len(oimp[0])-1)/math.sqrt(float(len(oimp[0])))\n",
    "                    #print(\"length of dmeanY[0] is {:}\\n\".format(len(dmeanY)))\n",
    "                    #oystd1 *= (len(dmeanY)-2)/math.sqrt(float(len(dmeanY)-1))\n",
    "                ostd = np.array([math.sqrt(ostd[i]**2+omeanstd[i]**2) for i in range(self.ny)])\n",
    "            else:\n",
    "                #oimp = np.array(pd[:][0]).T\n",
    "                oimp = np.array(np.array(pd).reshape(2*len(pd),self.ny)[::2]).T\n",
    "                obc = np.array([oimp[i].mean() for i in range(self.ny)])\n",
    "                simp = np.array(np.array(pd).reshape(2*len(pd),self.ny)[1::2]).T\n",
    "                ostd = np.array([[oimp[i].std(ddof=1), simp[i].mean()] for i in range(self.ny)])\n",
    "                oymean1 = np.array(dmeanY).mean(axis=0)\n",
    "                oystd1 = np.array(dmeanY).std(axis=0, ddof=1)\n",
    "            self.res = (scr, obc, ostd)\n",
    "            oy = np.array(self.data['Y']).T\n",
    "            oymean = np.array([oy[i].mean() for i in range(self.ny)]) * self.dmeanY\n",
    "            #oystd = np.array([oy[i].std(ddof=1) for i in range(self.ny)]) * self.dmeanY/math.sqrt(self.unlbl)\n",
    "            print(\"self.dstdY is {:}\".format(self.dstdY))\n",
    "            oystd = np.array(stdY).mean(axis=0) / math.sqrt(float(self.unlbl))\n",
    "            if False:\n",
    "                print(\"Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "               \\t {:} (re)sampling {:d} fits \\n \\\n",
    "               \\t score = {:}; Predicted Mean / Observed: \\\n",
    "               \\t {:} +- {:} / {:} +- {:} \\n\".format(self.nx, self.ndata, self.trn,self.bc, self.unlbl, \n",
    "                                                             self.tdset, self.nfit, \n",
    "                                                             scr, obc*self.dmeanY, ostd*abs(self.dmeanY),  \n",
    "                                                             oymean, oystd))\n",
    "            IR = ['R', 'I']\n",
    "            if 'CV' in self.tdset:\n",
    "                print(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                    \\t {:} (re)sampling {:d} fits \\n \\\n",
    "                    \\t scrall = {:}; \\n \\\n",
    "                    \\t score = {:}; \\n scrstd = {:}; \\n\\\n",
    "                    \\t Y's \\t Predicted Mean / Observed \\t Bias-correction \\t Score \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                    self.tdset, self.nfit, \n",
    "                                                    scr, scrmean0, scrstd0))\n",
    "                for i in range(self.ny): \n",
    "                    print(\"\\t Y{:d}.{:s} \\t {:8e} +- {:} / {:8e} +- {:} \\t {:8e} +- {:} \\t {:8e} +- {:}\".format(int(i/2), IR[i%2], \n",
    "                                                                               obc[i]*self.dmeanY[i], ostd[i]*abs(self.dmeanY[i]), \n",
    "                                                                              oymean[i], oystd[i], bs[i], bss[i], scrmean[i], scrstd[i]))\n",
    "            else:\n",
    "                print(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                    \\t {:} (re)sampling {:d} fits \\n \\\n",
    "                    \\t score = {:}; \\n \\\n",
    "                    \\t Y's \\t Predicted Mean / Observed: \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                    self.tdset, self.nfit, \n",
    "                                                    scr))\n",
    "                for i in range(self.ny): \n",
    "                    print(\"\\t Y{:d}.{:s} \\t {:8e} +- {:} / {:8e} +- {:} \".format(int(i/2), IR[i%2], \n",
    "                                                                               obc[i]*self.dmeanY[i], ostd[i]*abs(self.dmeanY[i]), \n",
    "                                                                              oymean1[i], oystd1[i]))\n",
    "            print('\\n\\n')\n",
    "            if 'CV' in self.tdset:\n",
    "                pf.write(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                \\t {:} (re)sampling {:d} fits \\n \\\n",
    "                \\t scrall = {:}; \\n \\\n",
    "                \\t score = {:}; \\n scrstd = {:}; \\n\\\n",
    "                \\t Y's \\t Predicted Mean / Observed \\t Bias-correction \\t Score: \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                self.tdset, self.nfit, \n",
    "                                                scr, scrmean0, scrstd0))#scr))\n",
    "                IR = ['R', 'I']\n",
    "                for i in range(self.ny): \n",
    "                    pf.write(\"\\t Y{:d}.{:s} \\t {:8e} +- {:} / {:8e} +- {:} \\t {:8e} +- {:} \\t {:8e} +- {:}\\n\".format(int(i/2), IR[i%2], \n",
    "                                                                           obc[i]*self.dmeanY[i], ostd[i]*abs(self.dmeanY[i]), \n",
    "                                                                          oymean[i], oystd[i], bs[i], bss[i], scrmean[i], scrstd[i]))\n",
    "            else:\n",
    "                pf.write(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                \\t {:} (re)sampling {:d} fits \\n \\\n",
    "                \\t score = {:}; \\n\\\n",
    "                \\t Y's \\t Predicted Mean / Observed: \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                self.tdset, self.nfit, \n",
    "                                                scr))\n",
    "                IR = ['R', 'I']\n",
    "                for i in range(self.ny): \n",
    "                    pf.write(\"\\t Y{:d}.{:s} \\t {:8e} +- {:} / {:8e} +- {:} \\n\".format(int(i/2), IR[i%2], \n",
    "                                                                           obc[i]*self.dmeanY[i], ostd[i]*abs(self.dmeanY[i]), \n",
    "                                                                          oymean1[i], oystd1[i]))\n",
    "        else:\n",
    "            print(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                \\t {:} (re)sampling {:d} fits \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                self.tdset, self.nfit))\n",
    "            if self.osave:\n",
    "                pf.write(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "                \\t {:} (re)sampling {:d} fits \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                                self.tdset, self.nfit))\n",
    "        if self.osave:\n",
    "            if self.anal:\n",
    "                if self.effmass:\n",
    "                    self.post_anal.print_effmass(self.tdset, pf, ppf=self.database.pltfile)\n",
    "                if self.ratio:\n",
    "                    self.post_anal.print_ratio3ptn2pt(self.tdset, pf, ppf=self.database.pltfile)\n",
    "            pf.write(\"\\n\\n\\n\")\n",
    "            pf.close()\n",
    "        if self.panal:\n",
    "            print(\"Merge tables\")\n",
    "            self.post_anal.merge_table()\n",
    "            print(\"Finished merging tables\")\n",
    "            # no need to save current analysis results\n",
    "            self.post_anal.drop_table()\n",
    "    \n",
    "    def print_fit(self, pd):\n",
    "        for r in pd:\n",
    "            print(r)\n",
    "    \n",
    "    # Do fits\n",
    "    def fit(self):\n",
    "        res = []\n",
    "        bc = []\n",
    "        pd = []\n",
    "        dmeanY = []\n",
    "        stdY = []\n",
    "        n=0\n",
    "        while self.isfit(): #for i in range(self.nfit):\n",
    "            if self.setup_data():\n",
    "                # Print data statistics\n",
    "                if False:#n == 1:\n",
    "                    print(\"Training data statistic\\n\")\n",
    "                    data = {}\n",
    "                    data['X'] = np.array(self.X).reshape(self.trn, self.nx)\n",
    "                    data['Y'] = np.array(self.Y).reshape(self.trn, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                    print(\"Bias correction data statistic\\n\")\n",
    "                    data['X'] = np.array(self.B).reshape(self.bc, self.nx)\n",
    "                    data['Y'] = np.array(self.C).reshape(self.bc, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                    print(\"Unlabeled data statistic\\n\")\n",
    "                    data['X'] = np.array(self.N).reshape(self.unlbl, self.nx)\n",
    "                    data['Y'] = np.array(self.P).reshape(self.unlbl, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                # yield to DL fitter\n",
    "                if self.fitter_DL is not None:\n",
    "                    res.append(self.fitter_DL.fit(self.X, self.Y, self.B, self.C))\n",
    "                elif self.pred:\n",
    "                    print(\"ny = {:} \\n\\n self.Y shape {:} X shape {:}\\n\\n\".format(self.ny, np.array(self.Y).shape, np.array(self.X).shape))\n",
    "                    res.append(np.array([self.model[i].fit(\n",
    "                        self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.X).tolist(), \n",
    "                        np.array(self.Y).T.tolist()[i]) for i in range(self.ny)]))\n",
    "                    print(\"finished fitting\\n\\n\")\n",
    "                #print(res[-1])\n",
    "                    bc.append(self.bias_crrt())\n",
    "                    print(bc[-1])\n",
    "                    pd.append(self.imp_prdt(bc[-1]))\n",
    "                    print(pd[-1])\n",
    "                    mn = np.array(self.P).mean(axis=0)\n",
    "                    print(\"mean of self.P is {:} \\n self.dmeanY is {:}\".format(mn, self.dmeanY))\n",
    "                    dmeanY.append(np.array(mn*self.dmeanY).tolist())\n",
    "                    stdY.append(np.array(np.array(self.P).std(axis=0, ddof=1)/math.sqrt(len(self.P))*self.dmeanY).tolist())\n",
    "                    print(\"std of self.P is {:}\\n\".format(stdY[-1]))\n",
    "                if self.panal:\n",
    "                    self.add_anal()\n",
    "                if False:#n == 1:\n",
    "                    print(\"Predicted data statistics\\n\")\n",
    "                    data = {'X': np.array(self.N).reshape(self.unlbl,self.nx), 'Y': np.array(self.p).T}\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                self.cleanup_data()\n",
    "                if self.print:\n",
    "                    self.print_fit(pd)\n",
    "                n+=1\n",
    "        if self.anal: \n",
    "            self.analyze(bc, pd, dmeanY, stdY)\n",
    "        return\n",
    "\n",
    "    def show_fit(self):\n",
    "        return\n",
    "            \n",
    "    def runraw(self):\n",
    "        par = [1, 0]\n",
    "        print(\"inifit\\n\")\n",
    "        self.inifit(par, par, 0)  \n",
    "        print(\"Doing fit\\n\")\n",
    "        self.fit()\n",
    "        #self.analyze()\n",
    "        return\n",
    "        \n",
    "    # runs over loops of input parameters\n",
    "    def run(self):\n",
    "        tlist = (tuple, list)\n",
    "        print(\"Running ML...\\n\")\n",
    "        for pi in range(len(self.prY)):\n",
    "            try:\n",
    "                oy = self.orY[pi]\n",
    "            except:\n",
    "                oy = self.orY[0]\n",
    "            try:\n",
    "                ox = self.orX[pi]\n",
    "            except:\n",
    "                ox = self.orX[0]\n",
    "            if isinstance(self.prY[pi], tlist):\n",
    "                py = self.prY[pi]\n",
    "            else:\n",
    "                py = [self.prY[pi]]\n",
    "            if self.prX is None:\n",
    "                px = None\n",
    "            else:\n",
    "                try:\n",
    "                    px = self.prX[pi]\n",
    "                except:\n",
    "                    px = self.prX[0]\n",
    "            if isinstance(self.zrY[pi], tlist):\n",
    "                zy = list(self.zrY[pi])\n",
    "            else:\n",
    "                zy = [self.zrY[pi]]\n",
    "            if self.zrX is None:\n",
    "                zx = None\n",
    "            else:\n",
    "                try:\n",
    "                    zx = self.zrX[pi]\n",
    "                except:\n",
    "                    zx = self.zrX[0]\n",
    "            print(\"X z's is {:}\".format(zx))\n",
    "            if False:\n",
    "                if isinstance(self.zrX[pi], tlist):\n",
    "                    zx = list(self.zrX[pi])\n",
    "                else:\n",
    "                    zx = [self.zrX[pi]]\n",
    "            for tsp in range(len(self.srY)):\n",
    "                if isinstance(self.srY[tsp], tlist):\n",
    "                    tsy = list(self.srY[tsp])\n",
    "                else:\n",
    "                    tsy = [self.srY[tsp]]\n",
    "                try:\n",
    "                    if isinstance(self.srX[tsp], tlist):\n",
    "                        tsx = list(self.srX[tsp])\n",
    "                    else:\n",
    "                        tsx = [self.srX[tsp]]\n",
    "                except:\n",
    "                    tsx = self.srX[0]\n",
    "                for ti in range(len(self.tr)):\n",
    "                    if isinstance(self.tr[ti], tlist):\n",
    "                        ty = list(self.tr[ti])\n",
    "                    else:\n",
    "                        ty = [self.tr[ti]]\n",
    "                    if None in ty:\n",
    "                        ty = None\n",
    "                    try:\n",
    "                        if isinstance(self.dtr[ti], tlist):\n",
    "                            dtx = self.dtr[ti]\n",
    "                        else:\n",
    "                            dtx = self.dtr\n",
    "                    except:\n",
    "                        dtx = self.dtr\n",
    "                    if False:\n",
    "                        tx = []\n",
    "                        for t,dt in product(ty, dtx):\n",
    "                            tx.append(t+dt)\n",
    "                        ttx = np.array(tx)\n",
    "                        ttx.sort()\n",
    "                        del tx\n",
    "                        tx = []\n",
    "                        tx.append(ttx[0])\n",
    "                        for i in range(1, ttx.size):\n",
    "                            if ttx[i] != tx[-1]:\n",
    "                                tx.append(ttx[i])\n",
    "                    parX = [ox, px, zx, tsx, ty, dtx]\n",
    "                    parY = [oy, py, zy, tsy, ty, None]\n",
    "                    print(py)\n",
    "                    print(zy)\n",
    "                    self.inifit(parX, parY, pi)\n",
    "                    #if True: #self.pre_anly:\n",
    "                    #    self.data_statistic(self.data)  \n",
    "                    self.fit()\n",
    "                    if SHOW:\n",
    "                        self.show_fit()\n",
    "                # spectrum only, ignore loop over 'T'\n",
    "                if zy == [self.database.NA]:\n",
    "                    break\n",
    "        return\n",
    "\n",
    "   \n",
    "\n",
    "def main(pfile, RandTrn, RandBC, RandUnl, noSaveRand, raw=False):\n",
    "    ml = ML_Regression(pfile, RandTrn, RandBC, RandUnl)\n",
    "    if raw:\n",
    "        ml.runraw()\n",
    "    else:\n",
    "        ml.run()\n",
    "    RandTrn = []\n",
    "    RandBC = []\n",
    "    RandUnl = []\n",
    "    if noSaveRand is False:\n",
    "        if ml.tdset == 'BS':\n",
    "            RandTrn = ml.Rtrn.copy()\n",
    "            RandBC = ml.Rbc.copy()\n",
    "            RandUnl = ml.Runl.copy()\n",
    "            pf = open('/Users/ruizi/Documents/ML/Samples.train', 'a')\n",
    "            pf.write('{:}\\n\\n'.format(ml.Rtrn))\n",
    "            pf.close()\n",
    "            pf = open('/Users/ruizi/Documents/ML/Samples.bc', 'a')\n",
    "            pf.write('{:}\\n\\n'.format(ml.Rbc))\n",
    "            pf.close()\n",
    "            pf = open('/Users/ruizi/Documents/ML/Samples.unlabel', 'a')\n",
    "            pf.write('{:}\\n\\n'.format(ml.Runl))\n",
    "            pf.close()\n",
    "        elif 'CV' in ml.tdset:\n",
    "            RandTrn = ml.Rm.copy()\n",
    "    ml.finalize()\n",
    "    return RandTrn, RandBC, RandUnl\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    if False:#for j in range(2):\n",
    "        for i in [250, 500, 750, 1000]:\n",
    "            main(open('/Users/ruizi/Documents/ML/input.pda.test.'+str(i),'r')) \n",
    "    noSaveRand = True\n",
    "    RandTrn = []\n",
    "    RandBC = []\n",
    "    RandUnl = []\n",
    "    for ff in [ \"pdf.kaon.ave\"]:#, \"pdf.kaon.ave1\"]:#, \"pdf.kaon.ave2\"]:#, \"pdf.kaon.ave1\", \"pdf.kaon.ave2\" ]:#, \"pdf.kaon.p\"]:#, \"pdf.z0\"]:\n",
    "        #for ntrn, nbc in product([50, 40], [100, 80, 60, 40]): #[ 1, 0.5, 0.2, 0.1, 0.01, 0.005, 0.001, 0.0005, 0.0001 ], [100, 200, 300, 400]): #ff in [\"pdf.k3\"]: \n",
    "        RandTrn = []\n",
    "        RandBC = []\n",
    "        RandUnl = []\n",
    "        if 'pdf' in ff:\n",
    "            m = 1\n",
    "            pf = open(\"/Users/ruizi/Documents/ML//params/GB\", 'a')\n",
    "            pf.write(\"lnrate: {:}\\nnestimator: {:}\\n\".format(0.01, 400))\n",
    "            pf.close()\n",
    "            for ntrn, nbc in product([60, 80, 100, 120], [60, 80, 100, 120]): #([50]): #nbc in product([100, 80], [100, 80]):\n",
    "                #nbc = ntrn\n",
    "                pf = open('/Users/ruizi/Documents/ML/input.'+ff+'.'+str(m),'a')\n",
    "                pf.write('ntrn: {:}\\nnbc: {:}\\n'.format(ntrn, nbc))\n",
    "                pf.close()\n",
    "                RandTrn = []\n",
    "                RandBC = []\n",
    "                RandUnl = [] \n",
    "                noSaveRand = False\n",
    "                RandTrn, RandBC, RandUnl = main(open('/Users/ruizi/Documents/ML/input.'+ff+'.'+str(m),'r'), RandTrn, RandBC, RandUnl, noSaveRand)\n",
    "                m += 1\n",
    "        else:\n",
    "            pf = open(\"/Users/ruizi/Documents/ML//params/GB\", 'a')\n",
    "            pf.write(\"lnrate: {:}\\nnestimator: {:}\\n\".format(0.1, 100))\n",
    "            pf.close()\n",
    "            m=1\n",
    "            for ntrn, nbc in product([50, 70, 90], [50, 70, 90]):\n",
    "                RandTrn = []\n",
    "                RandBC = []\n",
    "                RandUnl = []\n",
    "                noSaveRand = False\n",
    "                pf = open('/Users/ruizi/Documents/ML/input.'+ff+'.'+str(m),'a')\n",
    "                pf.write('ntrn: {:}\\nnbc: {:}\\n'.format(ntrn, nbc))\n",
    "                pf.close()\n",
    "                RandTrn, RandBC, RandUnl = main(open('/Users/ruizi/Documents/ML/input.'+ff+'.'+str(m),'r'),  RandTrn, RandBC, RandUnl, noSaveRand, True)\n",
    "                m += 1\n",
    "            #for rate, estm in product([ 0.5, 0.1, 0.01, 0.005, 0.001 ], [100, 200, 300, 400]):#[0.1, 0.01], [100, 300]):\n",
    "            #RandTrn = []\n",
    "            #for nbc in [100, 80, 60, 40]: \n",
    "            #RandBC = []\n",
    "            #RandUnl = []\n",
    "            #for rate, estm in product([0.1, 0.01], [100, 300]):\n",
    "    return\n",
    "    #for i in range(2,9):\n",
    "     #   main(open('/Users/ruizi/Documents/ML/input.'+str(i),'r'))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make heatmap plots on fitting scores for each channel of fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yaml as yl\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sbn\n",
    "import re\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "# maximum number of channels\n",
    "chmax = 2\n",
    "\n",
    "idate = [ '06192019.0{:2d}'.format(i) for i in range(18, 30)]#'0530', '0531' ]#, '0525' ]\n",
    "\n",
    "# return scores and its deviations from each output file\n",
    "def read(file): \n",
    "    scr = {}\n",
    "    err = {}\n",
    "    scr0 = {}\n",
    "    bs = {}\n",
    "    with open(file, 'r') as pf:\n",
    "        m = 0\n",
    "        stl = None\n",
    "        cont = False\n",
    "        for line in pf:\n",
    "            if 'unlbl' in line:\n",
    "                unlbl = int(line.split()[-2].split('/')[-1])\n",
    "            if re.search('Y\\d\\.(R|I)', line) is not None:\n",
    "                #print(line)\n",
    "                nf = line.split()\n",
    "                try:\n",
    "                    bs[nf[0]].append(math.sqrt((float(nf[6])-float(nf[1]))**2/float(nf[-7])**2/float(unlbl)))\n",
    "                    scr[nf[0]].append(float(nf[-3])+bs[nf[0]][-1]**2)#+bs[-1]**2/float(nf[-4]))/float(stl[m]))\n",
    "                    err[nf[0]].append(abs(float(nf[-1])/float(stl[m])))\n",
    "                    scr0[nf[0]].append(stl[m])\n",
    "                except:\n",
    "                    bs[nf[0]] = [math.sqrt((float(nf[6])-float(nf[1]))**2/(float(nf[-7]))**2/float(unlbl))]\n",
    "                    scr[nf[0]] = [float(nf[-3])+bs[nf[0]][-1]**2]#+bs[-1]**2/float(nf[-4]))/float(stl[m])]\n",
    "                    err[nf[0]] = [abs(float(nf[-1])/float(stl[m]))]\n",
    "                    scr0[nf[0]] = [stl[m]]\n",
    "                m += 1\n",
    "            l = line.split()\n",
    "            try:\n",
    "                if l[0] == 'score':\n",
    "                    stl = line.split('[')[1].split(']')[0].split()\n",
    "                    m = 0\n",
    "                    if ']' in line:\n",
    "                        cont = False\n",
    "                    else:\n",
    "                        cont = True\n",
    "                elif cont:\n",
    "                    stl.extend(line.split(']')[0].split())\n",
    "                    if ']' in line:\n",
    "                        cont = False\n",
    "            except:\n",
    "                pass\n",
    "        #print(err)\n",
    "        pf.close()\n",
    "    return scr, err, scr0, bs\n",
    "\n",
    "tabtemp = pds.DataFrame(dtype=float)#, columns=['100', '200', '300', '400'], index=[ '1', '0.5', '0.2', '0.1', '0.01', '0.005', '0.001', '0.0005', '0.0001' ])\n",
    "\n",
    "def make_table(par, file, ofile):\n",
    "    tab = {}\n",
    "    tabv = {}\n",
    "    tab0 = {}\n",
    "    tabbss = {}\n",
    "    n=0\n",
    "    print(\"file length is {:}\".format(len(file)))\n",
    "    for j in par:\n",
    "        for i in par[j]:\n",
    "            #print(n)\n",
    "            scrl, errl, scr0l, bs = read(file[n])\n",
    "            l=0\n",
    "            for erk in errl:\n",
    "                m=0\n",
    "                for err in errl[erk]:\n",
    "                    #print(\"err is \", err)\n",
    "                    if erk+'.'+str(m) in tab:\n",
    "                        tab[erk+'.'+str(m)].set_value(j, i, float(err))\n",
    "                        tabv[erk+'.'+str(m)].set_value(j, i, float(scrl[erk][m]))\n",
    "                        tab0[erk+'.'+str(m)].set_value(j, i, float(scr0l[erk][m]))\n",
    "                        tabbss[erk+'.'+str(m)].set_value(j, i, float(bs[erk][m]))\n",
    "                    else:\n",
    "                        tab[erk+'.'+str(m)] = pds.DataFrame(tabtemp)\n",
    "                        tab[erk+'.'+str(m)].set_value(j, i, float(err))\n",
    "                        tabv[erk+'.'+str(m)] = pds.DataFrame(tabtemp)\n",
    "                        tabv[erk+'.'+str(m)].set_value(j, i, float(scrl[erk][m]))\n",
    "                        tab0[erk+'.'+str(m)] = pds.DataFrame(tabtemp)\n",
    "                        tab0[erk+'.'+str(m)].set_value(j, i, float(scr0l[erk][m]))\n",
    "                        tabbss[erk+'.'+str(m)] = pds.DataFrame(tabtemp)\n",
    "                        tabbss[erk+'.'+str(m)].set_value(j, i, float(bs[erk][m]))\n",
    "                    m+=1\n",
    "            n+=1\n",
    "    pf = open(ofile, 'a+')\n",
    "    m = 0\n",
    "    try:\n",
    "        os.mkdir(ofile+'.plot')\n",
    "    except:\n",
    "        print(\"Warning: directory \"+ofile+\".plot/ already exists!\")\n",
    "    for key in tab:\n",
    "        fig, ax = mplot.subplots()\n",
    "        print(key+\" variance\")\n",
    "        print(tab[key])\n",
    "        ax = sbn.heatmap(tab[key], cmap=sbn.diverging_palette(220, 4, as_cmap=True))\n",
    "        mplot.show()\n",
    "        fig.savefig(ofile+'.plot/pvar.'+str(m)+'.pdf', format='pdf')\n",
    "        fig, ax = mplot.subplots()\n",
    "        print(key+\" test\")\n",
    "        print(tabv[key])\n",
    "        ax = sbn.heatmap(tabv[key], vmin=0.0, vmax=1.0, cmap=sbn.diverging_palette(220, 4, as_cmap=True))\n",
    "        mplot.show()\n",
    "        fig.savefig(ofile+'.plot/ptst.'+str(m)+'.pdf', format='pdf')\n",
    "        fig, ax = mplot.subplots()\n",
    "        print(key+\" train\")\n",
    "        print(tab0[key])\n",
    "        ax = sbn.heatmap(tab0[key], vmin=0.0, vmax=1.0, cmap=sbn.diverging_palette(220, 4, as_cmap=True))\n",
    "        mplot.show()\n",
    "        fig.savefig(ofile+'.plot/ptrn.'+str(m)+'.pdf', format='pdf')\n",
    "        #pf.write(key+\"\\n variance \\n {:} \\n\\n test \\n {:} \\n\\n train \\n {:} \\n\\n\".format(tab[key], tabv[key], tab0[key]))\n",
    "        fig, ax = mplot.subplots()\n",
    "        print(key+\" bcstd\")\n",
    "        print(tabbss[key])\n",
    "        ax = sbn.heatmap(tabbss[key], vmin=0.0, vmax=0.1, cmap=sbn.diverging_palette(220, 4, as_cmap=True))\n",
    "        mplot.show()\n",
    "        fig.savefig(ofile+'.plot/pbcstd.'+str(m)+'.pdf', format='pdf')\n",
    "        pf.write(key+\"\\n variance \\n {:} \\n\\n test \\n {:} \\n\\n train \\n {:} \\n\\nbcstd \\n {:} \\n\\n\".format(tab[key], tabv[key], tab0[key], tabbss[key]))\n",
    "        m += 1\n",
    "    pf.close()\n",
    "    del tab\n",
    "    del tabv\n",
    "    del tab0\n",
    "    del tabbss\n",
    "    return\n",
    "\n",
    "odir = '/Users/ruizi/Documents/ML/outputs/pdf/meson/ave'\n",
    "\n",
    "params = {}\n",
    "for i, j in product([0.1, 0.01, 0.005], [100, 200, 300, 400]):#[ 0.5, 0.1, 0.01, 0.005, 0.001 ], [100, 200, 300, 400]):# [ 1, 0.5, 0.2, 0.1, 0.01, 0.005, 0.001, 0.0005 ], [100, 200, 300, 400]):\n",
    "#for i, j in product([50,10,5], [100])\n",
    "    try:\n",
    "        params[str(i)].append(str(j))\n",
    "    except:\n",
    "        params[str(i)] = [str(j)]\n",
    "        \n",
    "for ch in range(chmax):\n",
    "    files = []\n",
    "    for d1, d2, f in os.walk(odir): \n",
    "        #print(d1)\n",
    "        for ddir in d2:\n",
    "            for dt in idate:\n",
    "                if dt in ddir:\n",
    "                    files.append(odir+'/'+ddir+'/CV1.'+str(ch)) \n",
    "        break\n",
    "    files.sort()\n",
    "    print(\"channel {:}\".format(ch))\n",
    "    make_table(params, files, odir+'/score.ch'+str(ch))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.random.seed(2019)\n",
    "print(\"{:}\".format(numpy.random.randint(0,50,10)))\n",
    "print(\"{:}\".format(numpy.random.randint(0,50,10)))\n",
    "\n",
    "a=numpy.array([[1,2], [3,4], [5,6]])\n",
    "print(a.mean(axis=1))\n",
    "print(abs(a))\n",
    "a=[[1,2], [3,4], [5,6]]\n",
    "print(a[0:1])\n",
    "print(['ML.06122019.0{:02d}'.format(i) for i in range(3, 13) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yaml as yl\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sbn\n",
    "import re\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "idir='/Users/ruizi/Documents/ML/outputs/pdf/'\n",
    "dirjk = ['ML.06112019.006', 'ML.06112019.014']\n",
    "key = ['50', '40']\n",
    "dirbs = ['ML.06122019.0{:02d}'.format(i) for i in range(3, 13) ]\n",
    "odir = '/Users/ruizi/Documents/ML/outputs/pdf/plots'\n",
    "p = [ 5, 7 ]\n",
    "trn = [ 50, 40 ]\n",
    "q=0\n",
    "for ch in [ '0', '2' ]:\n",
    "    errl = {}\n",
    "    ratiol = {}\n",
    "    m = 0\n",
    "    for d in dirjk:\n",
    "        file = idir+d+'/JK.'+ch\n",
    "        flag = 0\n",
    "        tmpe = {}\n",
    "        tmpr = {}\n",
    "        ct = 0\n",
    "        with open(file, 'r') as pf:\n",
    "            for line in pf:\n",
    "                if ('Ratio' in line) and ('Real' in line) and ('Observed' in line):\n",
    "                    flag += 1\n",
    "                    ct = 1\n",
    "                    if flag > 2:\n",
    "                        break\n",
    "                else:\n",
    "                    nn = line.split()\n",
    "                    if len(nn) < 1:\n",
    "                        ct = 0\n",
    "                        continue\n",
    "                    if (ct == 1) and ('g8' == nn[0]):\n",
    "                        if int(nn[3])==2+flag:\n",
    "                            tmpe[nn[3]] = [float(nn[-1])]\n",
    "                            tmpr[nn[3]] = [float(nn[4])]\n",
    "            pf.close()\n",
    "        errl[key[m]] = tmpe\n",
    "        ratiol[key[m]] = tmpr\n",
    "        m += 1\n",
    "    m = 0\n",
    "    for d in dirbs:\n",
    "        file = idir+d+'/BS.'+ch\n",
    "        flag = 0\n",
    "        ct = 0\n",
    "        with open(file, 'r') as pf:\n",
    "            for line in pf:\n",
    "                if ('Ratio' in line) and ('Real' in line) and ('Observed' in line):\n",
    "                    flag += 1\n",
    "                    ct = 1\n",
    "                    if flag > 2:\n",
    "                        break\n",
    "                else:\n",
    "                    nn = line.split()\n",
    "                    if len(nn) < 1:\n",
    "                        ct = 0\n",
    "                        continue\n",
    "                    if (ct == 1) and ('g8' == nn[0]):\n",
    "                        if int(nn[3])==2+flag:\n",
    "                            errl[key[m]][nn[3]].append(float(nn[-1]))\n",
    "                            ratiol[key[m]][nn[3]].append(float(nn[4]))\n",
    "                            print(\"BS: adding data at trn {:} t {:}\".format(key[m], nn[3]))\n",
    "            pf.close()\n",
    "        m += 1\n",
    "        if m == len(key):\n",
    "            m = 0\n",
    "    m = 0\n",
    "    for k in key:\n",
    "        for T in ratiol[k]:\n",
    "            l = len(ratiol[k][T])\n",
    "            r = [ratiol[k][T][0]]\n",
    "            e = [errl[k][T][0]]\n",
    "            r.extend(ratiol[k][T][m+1::len(key)])\n",
    "            e.extend(errl[k][T][m+1::len(key)])\n",
    "            fig, ax = mplot.subplots()\n",
    "            print('Y = {:} err={:}'.format(r, e))\n",
    "            ax.errorbar([0, 100, 110, 200, 210, 220], ratiol[k][T], yerr=errl[k][T], barsabove=True, fmt='o', capthick=10)\n",
    "            ax.set_title('Ratio: P = {:} trn = {:} t = {:}'.format(p[q], k, T))\n",
    "            mplot.show()\n",
    "            fig.savefig(odir+'/P{:}tn{:}t{:}.pdf'.format(p[q], k, T), format='pdf')\n",
    "        m += 1\n",
    "    q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yaml as yl\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as mplot\n",
    "import seaborn as sbn\n",
    "import re\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "odir='/Users/ruizi/Documents/ML/outputs/pdf/meson/ave'\n",
    "ofile = ['ML.06212019.0{:02d}'.format(i) for i in range(48, 64)]\n",
    "pred=[]\n",
    "obsv=[]\n",
    "prede=[]\n",
    "obsve=[]\n",
    "\n",
    "\n",
    "for file in ofile:\n",
    "    #print(file)\n",
    "    with open(odir+'/'+file+'/JK.0', 'r') as pf:\n",
    "        for line in pf:\n",
    "            if 'Bias correction data' in line: #'Y0.R' in line:\n",
    "                print(line)\n",
    "                n=line.split()\n",
    "                #pred.append(float(n[1]))\n",
    "                #prede.append(float(n[3]))\n",
    "                obsv.append(float(n[-3]))\n",
    "                obsve.append(float(n[-1]))\n",
    "x=[]\n",
    "y=[]\n",
    "for trn, bc in product([60,80,100,120], [60,80,100,120]):\n",
    "    x.append(trn+0.1*bc)\n",
    "    #y.append(trn+0.1*bc+1)\n",
    "\n",
    "fig,ax=mplot.subplots()\n",
    "ax.set_ylim(ymin=3.0e-7, ymax=3.9e-7)\n",
    "#ax.errorbar(x, pred, yerr=prede, barsabove=True, fmt='o', capthick=10)\n",
    "ax.errorbar(x, obsv, yerr=obsve, barsabove=True, fmt='s', capthick=10)\n",
    "mplot.show()\n",
    "fig.savefig(odir+'/PDFbc.pdf', format='pdf')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
