{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run statistic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data_anal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper of ML kernals for hadron correlators on lattice\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yaml as yl\n",
    "import sklearn.ensemble as sle\n",
    "import sklearn.tree as slt\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "# Algorithm depend. params\n",
    "TOL = 1.0e-4\n",
    "MIN_SSPLIT = 2\n",
    "# Minimum #fits\n",
    "MIN_FIT = 1\n",
    "# Minimum #training data\n",
    "MIN_TRAIN = 10\n",
    "# Minimum #bias correction (bc) data\n",
    "MIN_BC = 10\n",
    "# Minimum #unlabeled data\n",
    "MIN_PREDICT = 10\n",
    "PRINT = False\n",
    "SHOW = True\n",
    "\n",
    "# Class to ML fits \n",
    "#   pfile: parameter file\n",
    "class ML_Regression:\n",
    "    def __init__(self, pfile):\n",
    "        params = yl.load(pfile)\n",
    "        # model list: GradiantBoost, DecisionTree, RandomForest, DeepLearning(using Keras)\n",
    "        self.mllist = ['GB', 'DT', 'RF', 'DL']\n",
    "        # pick training data set: Jackknife, Bootstrap, Random\n",
    "        self.tdlist = ['JK', 'BS', 'RM']\n",
    "        #self.dfile = params['dfile']\n",
    "        # method to pick training data set: default to pick first self.trn data\n",
    "        self.nfit = MIN_FIT\n",
    "        self.print = PRINT\n",
    "        self.pre_anly = True\n",
    "        self.fitter_DL = None\n",
    "        try:\n",
    "            self.tdset = params['tdset']\n",
    "            if self.tdset in self.tdlist:\n",
    "                try:\n",
    "                    self.nfit = params['nfit']\n",
    "                except:\n",
    "                    self.nfit = MIN_FIT\n",
    "                if self.tdset == 'JK':\n",
    "                    # Jackknife index\n",
    "                    try:\n",
    "                        self.itdpar = params['tdpar']\n",
    "                    except:\n",
    "                        self.itdpar = 0\n",
    "                    self.tdpar = self.itdpar-1\n",
    "                    self.nfit = self.trn+1\n",
    "                    self.jk = False\n",
    "                if self.tdset == 'BS':\n",
    "                    self.nfit += 1\n",
    "                    self.bs = False\n",
    "            elif not isinstance(self.tdset, int):\n",
    "                print('Warning: Unknown training data subset identifier! Set to 0\\n')\n",
    "                self.tdset = 0\n",
    "        except:\n",
    "            self.tdset = 0\n",
    "        try:\n",
    "            self.odir = params['odir']\n",
    "            self.osave = True\n",
    "        except:\n",
    "            self.osave = False\n",
    "            self.ofile = None\n",
    "        self.pdir = params['pdir']\n",
    "        self.mlml = params['mlml']\n",
    "        pdfile = open(self.pdir+'/'+self.mlml,'r')\n",
    "        self.pf = yl.load(pdfile)\n",
    "        pdfile.close()\n",
    "        try:\n",
    "            self.anal = params['analysis']\n",
    "        except:\n",
    "            self.anal = False\n",
    "        if self.anal: \n",
    "            self.post_anal = ML_Analyze_PDF(params)\n",
    "            self.save_tmpfits = True\n",
    "            try:\n",
    "                self.effmass = params['effmass']\n",
    "            except:\n",
    "                self.effmass = False\n",
    "            try:\n",
    "                self.ratio = params['ratio']\n",
    "            except:\n",
    "                self.ratio = False\n",
    "        # list of Y momentum\n",
    "        self.prY = params['momentum_Y']\n",
    "        # list of Y z's\n",
    "        self.zrY = params['z_Y']\n",
    "        self.prX = params['momentum_X']\n",
    "        self.zrX = params['z_X']\n",
    "        # list of Y time slices\n",
    "        try:\n",
    "            self.tr = params['ts_Y']\n",
    "            if self.tr is None:\n",
    "                self.tr = [None]\n",
    "        except:\n",
    "            self.tr = [None]\n",
    "        # list of X & Y time differences\n",
    "        self.dtr = params['dts_X']\n",
    "        # number of sources per configuration\n",
    "        try:\n",
    "            self.tfold = params['nsrc']\n",
    "        except:\n",
    "            self.tfold = 0\n",
    "        self.ntrn = params['ntrn']\n",
    "        if isinstance(self.ntrn, (int, str)):\n",
    "            assert(int(self.ntrn) >= MIN_TRAIN)\n",
    "            self.ntrn = [int(self.ntrn)]\n",
    "        else:\n",
    "            assert(len(self.ntrn) == len(self.prX))\n",
    "        self.nbc = params['nbc']\n",
    "        if isinstance(self.nbc, (int, str)):\n",
    "            assert(int(self.nbc) >= MIN_BC)\n",
    "            self.nbc = [int(self.nbc)]\n",
    "        else:\n",
    "            assert(len(self.nbc) == len(self.prX))\n",
    "        # read in data stored in data pool 'database'\n",
    "        # params[]: \n",
    "        #     format (data format, 'raw','pdf'); \n",
    "        #     binsize (data bin); \n",
    "        #     ddir (data files directory)\n",
    "        #     dfile.x (X data filename); \n",
    "        #     dfile.y (Y data filename);\n",
    "        self.database = Data_IO(params, self.tdset)\n",
    "        self.data = None\n",
    "        self.ndata = 0\n",
    "        self.model = None\n",
    "        self.fitnow = None\n",
    "        self.isset = False\n",
    "        self.errscale = None\n",
    "        self.date = datetime.datetime.today().strftime('%m%d%Y')\n",
    "        # Data IO, moved to the io kernel \n",
    "        if False:\n",
    "        #if self.osave:\n",
    "            odir = self.odir+'/ML.'+self.date\n",
    "            sfix = ''\n",
    "            n = 1\n",
    "            flag = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    os.mkdir(odir+sfix)\n",
    "                    flag = 1\n",
    "                except:\n",
    "                    sfix = '.'+str(n)\n",
    "                    flag = 0\n",
    "                    n += 1\n",
    "                    #print(\"Warming: directory\"+self.odir+'/ML.'+self.date+\" already exist\")\n",
    "                if flag == 1:\n",
    "                    break\n",
    "            self.odir = odir+sfix\n",
    "            try:\n",
    "                os.mkdir(self.odir+'/plots')\n",
    "            except:\n",
    "                print(\"Warming: directory\"+self.odir+'/plots'+\" already exist\")\n",
    "            self.oheader_tag = None\n",
    "        #else:\n",
    "            self.ofile = None\n",
    "            self.pltfile = None\n",
    "        \n",
    "    # Initialize fits\n",
    "    # Select correlator characters, p (momentum), z (Wilson link lenght), t (sink time slice), etc., \n",
    "    #        data sets, and assign the fit model\n",
    "    def inifit(self, fdparX, fdparY, indx):\n",
    "        self.ftag = None\n",
    "        self.dtag = None\n",
    "        self.p = None\n",
    "        self.c = None\n",
    "        self.y = None\n",
    "        if self.del_data: \n",
    "            self.data = {}\n",
    "            deltagY, self.ftag, self.data['Y'], self.dmeanY, self.dstdY = self.database.select_data(fdparY, 'Y')\n",
    "            self.dtX, self.dtag, self.data['X'], self.dmeanX, self.dstdX = self.database.select_data(fdparX, 'X')       \n",
    "        self.ndata = self.data['X'].shape[0]\n",
    "        self.nx = self.data['X'].shape[1]\n",
    "        self.ny = self.data['Y'].shape[1]\n",
    "        print(\"Shape of X / Y : {:} / {:}\".format(self.nx, self.ny))\n",
    "        try:\n",
    "            self.trn = self.ntrn[indx]\n",
    "        except:\n",
    "            self.trn = self.ntrn[0]\n",
    "        try:\n",
    "            self.bc = self.nbc[indx]\n",
    "        except:\n",
    "            self.bc = self.nbc[0]\n",
    "        self.lbl = self.trn + self.bc\n",
    "        self.unlbl = self.ndata - self.lbl\n",
    "        self.bin = int((self.ndata+self.lbl-1)/self.lbl)\n",
    "        self.data_reorder()\n",
    "        if self.tdset == 'JK' or self.tdset == 'RM':\n",
    "            self.N = self.data['X'][self.lbl:]\n",
    "            self.P = self.data['Y'][self.lbl:]\n",
    "        if self.model != None:\n",
    "            del self.model\n",
    "        self.model = self.make_model()\n",
    "        self.isset = False\n",
    "        self.errscale = None\n",
    "        self.fitnow = 0\n",
    "        if self.osave:\n",
    "            self.database.dfile_mkheader(indx)\n",
    "        if self.anal:\n",
    "            print(\"Adding table\")\n",
    "            self.post_anal.add_table(self.database.NT, self.ndata, self.trn, self.bc, pztY=self.ftag, pztX=self.dtag)\n",
    "            print(\"Finishing adding table\")\n",
    "            \n",
    "    def isfit(self):\n",
    "        return self.fitnow < self.nfit\n",
    "        \n",
    "    # Reorder data (scatter)\n",
    "    def data_reorder(self):\n",
    "        tmpx = self.data['X']\n",
    "        tmpy = self.data['Y']\n",
    "        self.data['X'] = []\n",
    "        self.data['Y'] = []\n",
    "        for i in range(self.bin):\n",
    "            self.data['X'].extend(tmpx[i::self.bin])\n",
    "            self.data['Y'].extend(tmpy[i::self.bin])\n",
    "        del tmpx\n",
    "        del tmpy\n",
    "\n",
    "    # build up the fit model\n",
    "    def make_model(self):\n",
    "        assert(self.mlml in self.mllist) \n",
    "        if self.mlml == 'GB':\n",
    "            return self.make_model_GB()\n",
    "        elif self.mlml == 'DT':\n",
    "            return self.make_model_DT()\n",
    "        elif self.mlml == 'RF':\n",
    "            return self.make_model_RF()\n",
    "        else:\n",
    "            return self.make_model_DL()\n",
    "            \n",
    "    # Gradient Boosting\n",
    "    def make_model_GB(self):\n",
    "        self.GB_nestimator = self.pf['nestimator']\n",
    "        self.GB_lnrate = self.pf['lnrate']\n",
    "        try:\n",
    "            self.GB_lossfunc = self.pf['lossfunc']\n",
    "        except:\n",
    "            self.GB_lossfunc = 'ls'\n",
    "        self.GB_ssample = float(self.trn) / float(self.ndata)\n",
    "        try:\n",
    "            self.GB_mdth = self.pf['max_depth']\n",
    "        except:\n",
    "            self.GB_mdth = 3\n",
    "        try:\n",
    "            self.GB_tol = self.pf['lntol']\n",
    "        except:\n",
    "            self.GB_tol = TOL\n",
    "        model = [ sle.GradientBoostingRegressor(loss=self.GB_lossfunc, learning_rate=self.GB_lnrate, \n",
    "                                             n_estimators=self.GB_nestimator, max_depth=self.GB_mdth, \n",
    "                                             subsample=1.0,#self.GB_ssample,\n",
    "                                            tol=self.GB_tol)\n",
    "                 for i in range(self.ny) ]\n",
    "        return model\n",
    "        \n",
    "    # Decistion Tree\n",
    "    def make_model_DT(self):\n",
    "        try:\n",
    "            self.DT_ctr = self.pf['criterion']\n",
    "        except:\n",
    "            self.DT_ctr = 'mse'\n",
    "        self.DT_mdth = None\n",
    "        self.DT_mspt = None\n",
    "        try:\n",
    "            self.DT_mspt = self.pf['min_samples_split']\n",
    "        except:\n",
    "            try:\n",
    "                self.DT_mdth = self.pf['max_depth']\n",
    "                self.DT_mspt = None\n",
    "            except:\n",
    "                self.DT_mspt = MIN_SSPLIT\n",
    "                self.DT_mdth = None\n",
    "        model = [ slt.DecisionTreeRegressor(criterion=self.DT_ctr, max_depth=self.DT_mdth,\n",
    "                                        min_samples_split=self.DT_mspt)\n",
    "                 for i in range(self.ny) ]\n",
    "        return model\n",
    "            \n",
    "    # Random Foreast\n",
    "    def make_model_RF(self):\n",
    "        # FIXME\n",
    "        return None\n",
    "    \n",
    "    def make_model_DL(self):\n",
    "        self.fitter_DL = DL_Regression(self.pf, self.ny)\n",
    "        return self.fitter_DL.model\n",
    "    \n",
    "    def make_oheader(self, parY, parX, indx):\n",
    "        self.database.dfile_mkheader()\n",
    "        return\n",
    "    \n",
    "    # set up data: Train [X,Y]; BC [B,C]; Unlabeled [N,P]\n",
    "    def setup_data(self):\n",
    "        self.fitnow += 1\n",
    "        if self.save_tmpfits: \n",
    "            self.post_anal.append_table()\n",
    "        if self.isset:\n",
    "            return True\n",
    "        if isinstance(self.tdset, int):\n",
    "            try:\n",
    "                self.X = self.data['X'][:,self.tdset:self.tdset+self.trn]\n",
    "                self.Y = self.data['Y'][:,self.tdset:self.tdset+self.trn]\n",
    "                self.B = self.data['X'][self.tdset+self.trn:self.tdset+self.trn+self.bc]\n",
    "                self.C = self.data['Y'][self.tdset+self.trn:self.tdset+self.trn+self.bc]\n",
    "            except:\n",
    "                print('Labeled data subset out of index range!\\n')\n",
    "                sys.exit()\n",
    "            self.N = list(self.data['X'][self.tdset+self.lbl:])\n",
    "            self.P = list(self.data['Y'][self.tdset+self.lbl:])\n",
    "            if self.tdset > 0:\n",
    "                self.N.append(self.data['X'][:self.tdset])\n",
    "                self.P.append(self.data['Y'][:self.tdset])\n",
    "            self.tdset+=1\n",
    "        else:\n",
    "            if self.tdset == 'JK':\n",
    "                if self.jk: \n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    self.tdpar+=1\n",
    "                    if self.tdpar < 0 or self.tdpar > self.trn:\n",
    "                        return self.isset\n",
    "                    if self.tdpar > 0:\n",
    "                        self.X.extend(self.data['X'].slice(None,self.tdpar))\n",
    "                        self.Y.extend(self.data['Y'].slice(None,self.tdpar))\n",
    "                    self.X.append(self.data['X'].slice(self.tdpar+1,self.trn+1))\n",
    "                    self.Y.append(self.data['Y'].slice(self.tdpar+1,self.trn+1))\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.B.extend(self.data['X'][self.trn+1:self.lbl])\n",
    "                    self.B.extend(self.data['X'][self.tdpar])\n",
    "                    self.C.extend(self.data['Y'][self.trn+1:self.lbl])\n",
    "                    self.C.extend(self.data['Y'][self.tdpar])\n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    self.N = self.data['X'][self.lbl:]\n",
    "                    self.P = self.data['Y'][self.lbl:]\n",
    "                    self.jk = True\n",
    "            elif self.tdset == 'BS':\n",
    "                if self.bs:\n",
    "                    self.X = []\n",
    "                    self.Y = []\n",
    "                    self.B = []\n",
    "                    self.C = []\n",
    "                    self.N = []\n",
    "                    self.P = []\n",
    "                    for i in range(self.trn):\n",
    "                        r = np.random.randint(0,self.lbl)\n",
    "                        self.X.append(self.data['X'][r])\n",
    "                        self.Y.append(self.data['Y'][r])\n",
    "                    for i in range(self.bc):\n",
    "                        r = np.random.randint(0,self.lbl)\n",
    "                        self.B.append(self.data['X'][r])\n",
    "                        self.C.append(self.data['Y'][r])\n",
    "                    for i in range(self.unlbl):\n",
    "                        r = np.random.randint(self.lbl,self.ndata)\n",
    "                        self.N.append(self.data['X'][r])\n",
    "                        self.P.append(self.data['Y'][r])  \n",
    "                else:\n",
    "                    self.X = self.data['X'][:self.trn]\n",
    "                    self.Y = self.data['Y'][:self.trn]\n",
    "                    self.B = self.data['X'][self.trn:self.lbl]\n",
    "                    self.C = self.data['Y'][self.trn:self.lbl]\n",
    "                    self.N = self.data['X'][self.lbl:]\n",
    "                    self.P = self.data['Y'][self.lbl:]\n",
    "                    self.bs = True\n",
    "            else:\n",
    "                pm = np.random.permutation(self.lbl)\n",
    "                self.X = [self.data['X'][pm[i]] for i in range(self.trn)]\n",
    "                self.B = [self.data['X'][pm[i]] for i in range(self.trn,self.lbl)]\n",
    "                self.Y = [self.data['Y'][pm[i]] for i in range(self.trn)]\n",
    "                self.C = [self.data['Y'][pm[i]] for i in range(self.trn,self.lbl)]\n",
    "        self.isset = True\n",
    "        return self.isset\n",
    "        \n",
    "    def del_data(self):\n",
    "        if self.data == None:\n",
    "            return True\n",
    "        del self.data['X'][:]\n",
    "        del self.data['Y'][:]\n",
    "        self.data = None\n",
    "        del self.dmeanX\n",
    "        del self.dmeanY\n",
    "        del self.dstdY\n",
    "        del self.dstdX\n",
    "        self.dmeanX = None\n",
    "        self.dmeanY = None\n",
    "        self.dstdY = None\n",
    "        self.dstdX = None\n",
    "        return True\n",
    "    \n",
    "    # clean up data\n",
    "    def cleanup_data(self):\n",
    "        if self.isset is False:\n",
    "            return \n",
    "        if self.tdset in self.tdlist:\n",
    "            del self.X[:]\n",
    "            del self.Y[:]\n",
    "            del self.B[:]\n",
    "            del self.C[:]\n",
    "        if self.tdset == 'BS' or isinstance(self.tdset, int):\n",
    "            del self.N[:]\n",
    "            del self.P[:]\n",
    "        self.isset = False\n",
    "        return\n",
    "    \n",
    "    # Plot data statistics: histograms, density, correlations\n",
    "    def data_statistic(self, data, tag = None):\n",
    "        ddf = Dataframe(data, tag=tag)\n",
    "        print(ddf.data.describe())\n",
    "        binmin, atc = ddf.autocorr(0.1)\n",
    "        print('Data blocksize {:d} with autocorrelation {:f} \\n'.format(binmin, atc))\n",
    "        ddf.hist((self.nx, None))#,self.database.pltfile)\n",
    "        #ddf.density((0,self.nx))#, self.database.pltfile)\n",
    "        ddf.density((self.nx,None))#,self.database.pltfile)\n",
    "        #corrl = ddf.data.corr()\n",
    "        #print(corrl)\n",
    "        ddf.covplot(prange=((0, self.nx), (self.nx, None)))#, out=self.database.pltfile)\n",
    "        return\n",
    "        \n",
    "\n",
    "    # Prediction bias Correction\n",
    "    def bias_crrt(self):\n",
    "        if self.c is not None:\n",
    "            del self.c\n",
    "            self.c = None\n",
    "        if self.p is not None:\n",
    "            del self.p\n",
    "            self.p = None\n",
    "        if self.y is not None:\n",
    "            del self.y\n",
    "            self.y = None\n",
    "        self.c = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.B).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        self.p = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.N).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        C_arr = np.ndarray(shape=(self.bc,self.ny),buffer=np.array(self.C)).T\n",
    "        # Prediction matrix of size ny*ndata\n",
    "        self.y = np.array([self.model[i].predict(\n",
    "                self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.X).tolist()) \n",
    "                            for i in range(self.ny)])\n",
    "        predata = np.array([self.model[i].predict(\n",
    "            self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.data['X']).tolist())  \n",
    "                            for i in range(self.ny)])\n",
    "        print(predata.shape)\n",
    "        omat = np.ndarray(shape=(2*self.ny, self.ndata), \n",
    "                          buffer=np.array([\n",
    "                              predata.tolist(), \n",
    "                              np.array(self.data['Y']).T.tolist()]))\n",
    "                     #     dtype=float)\n",
    "        # generate covariance matrix, predictions first\n",
    "        ocov = np.cov(omat)\n",
    "        print('shape of OCOV: {:}'.format(ocov.shape))\n",
    "        # Bias correction equation\n",
    "        obc = np.array([self.p[i].mean() + C_arr[i].mean() - self.c[i].mean() for i in range(self.ny)])\n",
    "        for o in obc:\n",
    "            print(o)\n",
    "        s2 = np.array([ocov[i,i]/ocov[i+self.ny,i+self.ny] for i in range(self.ny)])\n",
    "        r = np.array([(ocov[i,i+self.ny]**2/(ocov[i,i]*ocov[i+self.ny,i+self.ny])) for i in range(self.ny)])\n",
    "        osigma = np.array([ocov[i+self.ny,i+self.ny] for i in range(self.ny)])\n",
    "        srs2r = np.array([math.sqrt(s2[i]*r[i]) for i in range(self.ny)])\n",
    "        bcvar = osigma/self.lbl*(s2*self.lbl/self.unlbl + (1.+s2-2.*srs2r)*self.lbl/self.bc)\n",
    "        if self.save_tmpfits:\n",
    "            #self.post_anal.extend_table({\"ycov\": ocov})\n",
    "          #  self.post_anal.extend_table({\"ymean\": obc})\n",
    "           # self.post_anal.extend_table({\"y\": omat})\n",
    "            if False: #for i in range(self.ny):\n",
    "                print(\"{:}: {:}\".format(self.ftag[i], np.array(self.Y).T[i]))\n",
    "            self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=np.array(self.Y).T, dbc=np.array(self.C).T, \n",
    "                                    dunlbl=np.array(self.P).T, pred=False, overwrite=True)\n",
    "            self.post_anal.add_data(tag=self.ftag, dscale=self.dmeanY, \n",
    "                                    dtrn=self.y, dbc=self.c, \n",
    "                                    dunlbl=self.p, pred=None, overwrite=True)\n",
    "            if self.effmass:\n",
    "                self.post_anal.effmass(tag=self.ftag, pred=False)\n",
    "                self.post_anal.effmass(tag=self.ftag, pred=True)\n",
    "            if self.ratio:\n",
    "                self.post_anal.add_data(tag=self.dtag, dscale=self.dmeanX, dtrn=np.array(self.X).T, \n",
    "                                        dbc=np.array(self.B).T, dunlbl=np.array(self.N).T, \n",
    "                                        pred=False, NT=self.database.NT, is2pt=True)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, pred=False)\n",
    "                self.post_anal.ratio3ptn2pt(tag=self.ftag, pred=True)\n",
    "        if self.errscale is None:\n",
    "            self.errscale = (s2*self.lbl/self.unlbl + (1.+s2-2.*srs2r)*self.lbl/self.bc)/self.lbl\n",
    "            self.errscale = np.array([math.sqrt(self.errscale[i]) for i in range(self.ny)])\n",
    "            print(\"Correlation coefficient between Pred. & Obsd. {:}\".format([math.sqrt(r[i]) for i in range(self.ny)]))\n",
    "            print(\"error scale: {:}\".format(self.errscale))\n",
    "            if False: #if self.anal:\n",
    "                self.post_anal.extend_table('errscl', self.errscale)\n",
    "            if self.osave: \n",
    "                pf = open(self.database.ofile, 'a+')\n",
    "                pf.write(\"Correlation coefficient between Pred. & Obsd. {:}\\n\".format([math.sqrt(r[i]) for i in range(self.ny)]))\n",
    "                pf.write(\"error scale: {:}\\n\".format(self.errscale))\n",
    "                pf.close()\n",
    "        return (obc, np.array([math.sqrt(bcvar[i]) for i in range(self.ny)]))\n",
    "    \n",
    "    def imp_prdt(self, bc):\n",
    "        return bc\n",
    "        \n",
    "    # Post-fits analysis\n",
    "    def analyze(self, bc, pd):\n",
    "        scr = np.array([self.model[i].score(\n",
    "            self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.data['X']).tolist(), \n",
    "            np.array(self.data['Y']).T.tolist()[i]) for i in range(self.ny)])\n",
    "        if self.tdset == 'BS' or self.tdset == 'JK':\n",
    "            oimp = np.array(np.array(pd[1:]).reshape(2*len(pd[1:]),self.ny)[::2]).T\n",
    "#            print(oimp)\n",
    "            omean = np.array([oimp[i].mean() for i in range(self.ny)])\n",
    " #           print(omean)\n",
    "            ostd = np.array([oimp[i].std() for i in range(self.ny)])\n",
    "            if self.tdset == 'BS':\n",
    "                print(pd[0][0])\n",
    "                obc = 2.*pd[0][0]-omean\n",
    "            else:\n",
    "                obc = self.lbl*pd[0][0]-(self.lbl-1)*omean\n",
    "                ostd *= (len(oimp)-1)**2\n",
    "        else:\n",
    "            oimp = np.array(pd[:][0]).T\n",
    "            obc = np.array([oimp[i].mean() for i in range(self.ny)])\n",
    "            ostd = np.array([oimp[i].std() for i in range(self.ny)])\n",
    "        self.res = (scr, obc, ostd)\n",
    "        oy = np.array(self.data['Y']).T\n",
    "        oymean = np.array([oy[i].mean() for i in range(self.ny)]) * self.dmeanY\n",
    "        oystd = np.array([oy[i].std() for i in range(self.ny)]) * self.dstdY/math.sqrt(self.unlbl)\n",
    "        if False:\n",
    "            print(\"Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "           \\t {:} (re)sampling {:d} fits \\n \\\n",
    "           \\t score = {:}; Predicted Mean / Observed: \\\n",
    "           \\t {:} +- {:} / {:} +- {:} \\n\".format(self.nx, self.ndata, self.trn,self.bc, self.unlbl, \n",
    "                                                         self.tdset, self.nfit, \n",
    "                                                         scr, obc*self.dmeanY, ostd*self.dmeanY,  \n",
    "                                                         oymean, oystd))\n",
    "        print(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "            \\t {:} (re)sampling {:d} fits \\n \\\n",
    "            \\t score = {:}; \\n\\\n",
    "            \\t Y's \\t Predicted Mean / Observed: \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                            self.tdset, self.nfit, \n",
    "                                            scr))\n",
    "        IR = ['R', 'I']\n",
    "        for i in range(self.ny): \n",
    "            print(\"\\t Y{:d}.{:s} \\t {:8e} +- {:8e} / {:8e} +- {:8e} \".format(int(i/2), IR[i%2], \n",
    "                                                                       obc[i]*self.dmeanY[i], ostd[i]*self.dmeanY[i], \n",
    "                                                                      oymean[i], oystd[i]))\n",
    "        print('\\n\\n')\n",
    "        if False:#if self.anal:\n",
    "            if self.effmass:\n",
    "                self.post_anal.print_effmass(self.tdset)\n",
    "            if self.ratio:\n",
    "                self.post_anal.print_ratio3ptn2pt(self.tdset)\n",
    "        if self.osave:\n",
    "            pf = open(self.database.ofile, 'a+')\n",
    "            pf.write(\"\\n Analysis result: {:d} * {:d} data {:d}/{:d}/{:d} tr/bc/unlbl; \\n \\\n",
    "            \\t {:} (re)sampling {:d} fits \\n \\\n",
    "            \\t score = {:}; \\n\\\n",
    "            \\t Y's \\t Predicted Mean / Observed: \\n\".format(self.nx, self.ndata, self.trn, self.bc, self.unlbl, \n",
    "                                            self.tdset, self.nfit, \n",
    "                                            scr))\n",
    "            IR = ['R', 'I']\n",
    "            for i in range(self.ny): \n",
    "                pf.write(\"\\t Y{:d}.{:s} \\t {:8e} +- {:8e} / {:8e} +- {:8e} \\n\".format(int(i/2), IR[i%2], \n",
    "                                                                       obc[i]*self.dmeanY[i], ostd[i]*self.dmeanY[i], \n",
    "                                                                      oymean[i], oystd[i]))\n",
    "            if self.anal:\n",
    "                if self.effmass:\n",
    "                    self.post_anal.print_effmass(self.tdset, pf, ppf=self.database.pltfile)\n",
    "                if self.ratio:\n",
    "                    self.post_anal.print_ratio3ptn2pt(self.tdset, pf, ppf=self.database.pltfile)\n",
    "            pf.write(\"\\n\\n\\n\")\n",
    "            pf.close()\n",
    "        if self.anal:\n",
    "            print(\"Merge tables\")\n",
    "            self.post_anal.merge_table()\n",
    "            print(\"Finished merging tables\")\n",
    "    \n",
    "    def print_fit(self, pd):\n",
    "        for r in pd:\n",
    "            print(r)\n",
    "    \n",
    "    # Do fits\n",
    "    def fit(self):\n",
    "        res = []\n",
    "        bc = []\n",
    "        pd = []\n",
    "        n=0\n",
    "        while self.isfit(): #for i in range(self.nfit):\n",
    "            if self.setup_data():\n",
    "                # Print data statistics\n",
    "                if False:#n == 1:\n",
    "                    print(\"Training data statistic\\n\")\n",
    "                    data = {}\n",
    "                    data['X'] = np.array(self.X).reshape(self.trn, self.nx)\n",
    "                    data['Y'] = np.array(self.Y).reshape(self.trn, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                    print(\"Bias correction data statistic\\n\")\n",
    "                    data['X'] = np.array(self.B).reshape(self.bc, self.nx)\n",
    "                    data['Y'] = np.array(self.C).reshape(self.bc, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                    print(\"Unlabeled data statistic\\n\")\n",
    "                    data['X'] = np.array(self.N).reshape(self.unlbl, self.nx)\n",
    "                    data['Y'] = np.array(self.P).reshape(self.unlbl, self.ny)\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                # yield to DL fitter\n",
    "                if self.fitter_DL is not None:\n",
    "                    res.append(self.fitter_DL.fit(self.X, self.Y, self.B, self.C))\n",
    "                else:\n",
    "                    print(\"ny = {:}\".format(self.ny))\n",
    "                    res.append(np.array([self.model[i].fit(\n",
    "                        self.database.select_T(self.dtag, self.dtX, self.ftag[i], self.X).tolist(), \n",
    "                        np.array(self.Y).T.tolist()[i]) for i in range(self.ny)]))\n",
    "                #print(res[-1])\n",
    "                    bc.append(self.bias_crrt())\n",
    "                    print(bc[-1])\n",
    "                    pd.append(self.imp_prdt(bc[-1]))\n",
    "                    print(pd[-1])\n",
    "                if False:#n == 1:\n",
    "                    print(\"Predicted data statistics\\n\")\n",
    "                    data = {'X': np.array(self.N).reshape(self.unlbl,self.nx), 'Y': np.array(self.p).T}\n",
    "                    self.data_statistic(data, {'X': self.dtag, 'Y': self.ftag})\n",
    "                self.cleanup_data()\n",
    "                if self.print:\n",
    "                    self.print_fit(pd)\n",
    "                n+=1\n",
    "        if self.anal: \n",
    "            self.analyze(bc, pd)\n",
    "\n",
    "    def show_fit(self):\n",
    "        return\n",
    "            \n",
    "    # runs over loops of input parameters\n",
    "    def run(self):\n",
    "        tlist = (tuple, list)\n",
    "        print(\"Running ML...\\n\")\n",
    "        for pi in range(len(self.prY)):\n",
    "            if isinstance(self.prY[pi], tlist):\n",
    "                py = list(self.prY[pi])\n",
    "            else:\n",
    "                py = [self.prY[pi]]\n",
    "            if isinstance(self.prX[pi], tlist):\n",
    "                px = list(self.prX[pi])\n",
    "            else:\n",
    "                px = [self.prX[pi]]\n",
    "            if isinstance(self.zrY[pi], tlist):\n",
    "                zy = list(self.zrY[pi])\n",
    "            else:\n",
    "                zy = [self.zrY[pi]]\n",
    "            if isinstance(self.zrX[pi], tlist):\n",
    "                zx = list(self.zrX[pi])\n",
    "            else:\n",
    "                zx = [self.zrX[pi]]\n",
    "            for ti in range(len(self.tr)):\n",
    "                if isinstance(self.tr[ti], tlist):\n",
    "                    ty = list(self.tr[ti])\n",
    "                else:\n",
    "                    ty = [self.tr[ti]]\n",
    "                if None in ty:\n",
    "                    ty = None\n",
    "                try:\n",
    "                    if isinstance(self.dtr[ti], tlist):\n",
    "                        dtx = self.dtr[ti]\n",
    "                    else:\n",
    "                        dtx = self.dtr\n",
    "                except:\n",
    "                    dtx = self.dtr\n",
    "                if False:\n",
    "                    tx = []\n",
    "                    for t,dt in product(ty, dtx):\n",
    "                        tx.append(t+dt)\n",
    "                    ttx = np.array(tx)\n",
    "                    ttx.sort()\n",
    "                    del tx\n",
    "                    tx = []\n",
    "                    tx.append(ttx[0])\n",
    "                    for i in range(1, ttx.size):\n",
    "                        if ttx[i] != tx[-1]:\n",
    "                            tx.append(ttx[i])\n",
    "                parX = [px, zx, ty, dtx]\n",
    "                parY = [py, zy, ty, None]\n",
    "                print(py)\n",
    "                print(zy)\n",
    "                self.inifit(parX, parY, pi)\n",
    "                if False:#self.pre_anly:\n",
    "                    self.data_statistic(self.data)  \n",
    "                self.fit()\n",
    "                if SHOW:\n",
    "                    self.show_fit()\n",
    "   \n",
    "\n",
    "def main(pfile):\n",
    "    ml = ML_Regression(pfile)\n",
    "    ml.run()\n",
    "    return 0\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main(open('input_param_filename','r'))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
